{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "Referencing https://becominghuman.ai/building-an-image-classifier-using-deep-learning-in-python-totally-from-a-beginners-perspective-be8dbaf22dd8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Reshape, concatenate,  Reshape, Flatten\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Dropout, RepeatVector, Permute, Activation,Lambda\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten,multiply,SpatialDropout2D\n",
    "from keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.backend import clear_session\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.layers import MaxPooling2D, Input, Dense, Flatten ,AveragePooling2D\n",
    "\n",
    "from keras.optimizers import Adam,rmsprop,SGD\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.initializers import glorot_normal\n",
    "from keras import regularizers\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from urllib import request\n",
    "import imutils\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "from glob import glob\n",
    "import keras,math\n",
    "import cv2 as cv \n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.layers import Conv2D, UpSampling2D, InputLayer, Conv2DTranspose, Reshape ,MaxPooling2D, advanced_activations\n",
    "from keras.layers import concatenate, Concatenate,Dense, Flatten,SeparableConv2D,LeakyReLU,GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization, RepeatVector, Permute, Activation, Reshape, Flatten,Multiply\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "\n",
    "from keras.layers import Lambda,Add,Dropout,SpatialDropout2D,DepthwiseConv2D,normalization\n",
    "from keras.models import Sequential, Model \n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.backend import clear_session\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from keras.layers import MaxPooling2D, Input, Dense, Flatten,ThresholdedReLU\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.gridspec as gridspec\n",
    " \n",
    "import tensorflow as tf \n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    " \n",
    "# aita die akta tensor e sob image k nie astasi\n",
    " \n",
    "from keras.layers import  Input,Conv2D,BatchNormalization,Activation,Lambda,Subtract,concatenate,Add,merge,add\n",
    "#from SpectralNormalizationKeras import DenseSN, ConvSN2D\n",
    "\n",
    "from keras.layers import  Input,Conv2D,BatchNormalization,Activation,Lambda,Subtract,concatenate,Add,merge,add\n",
    "#from SpectralNormalizationKeras import DenseSN, ConvSN2D\n",
    " \n",
    "from keras.optimizers import Adam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4198064761326699"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z=random.randn(200)\n",
    "x=list()\n",
    "for i in range(len(z)):\n",
    "    d=z[i]\n",
    "    x.append(d)\n",
    "    \n",
    "y=np.asarray(x)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "di= 256\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func.arcl import unt2,unt3,w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(x):\n",
    "    x=BatchNormalization()(x)\n",
    "    x4 = Activation('softplus')(x)\n",
    "    x4=Activation('tanh')(x4)\n",
    "    y = Lambda(lambda x: x[0]*x[1])([x4,x])\n",
    "    return y\n",
    "\n",
    "def swish(x):\n",
    "    #x=BatchNormalization()(x)\n",
    "    x1 = Activation('relu')(x)\n",
    "    x2 = Activation('sigmoid')(x)\n",
    "    y = Lambda(lambda x: x[0]*x[1])([x2,x])\n",
    "    return y\n",
    "\n",
    "def poold(x):\n",
    "    m=MaxPool2D(pool_size=5, strides=1,padding='same')(x)\n",
    "    a=AveragePooling2D(pool_size=5, strides=1,padding='same')(x)\n",
    "    ad=Lambda(lambda x: x[0]+x[1])([m,a])\n",
    "    av=Lambda(lambda x: x*0.5)(ad)\n",
    "    y=Lambda(lambda x: x[0]+x[1])([x,av])\n",
    " \n",
    " \n",
    "def cnf(z,f):\n",
    "    return Conv2D(f, kernel_size=5, strides=1,padding='same',activation=\"relu\",kernel_initializer='he_normal',\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(z)\n",
    "\n",
    "def cnh(z,f,k,s):\n",
    "    return Conv2D(f, kernel_size=k, strides=s,padding='same',activation=\"relu\",kernel_initializer='he_normal',\n",
    "                kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(z)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "def actc(x):      \n",
    "    x1 = Activation('relu')(x)\n",
    "    x2 = Activation('sigmoid')(x)\n",
    "    x3 = Lambda(lambda x: x[0]*x[1])([x2,x])\n",
    "    x4 = Activation('softplus')(x)\n",
    "    x4=Activation('tanh')(x4)\n",
    "    x5 = Lambda(lambda x: x[0]*x[1])([x4,x])\n",
    "    c1= Conv2D(5, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')(x1)  \n",
    "    c2= Conv2D(5, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')(x3)  \n",
    "    c3= Conv2D(5, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')(x5)  \n",
    "    cx=concatenate([c1,c2,c3], axis = 3)\n",
    "    #cx= BatchNormalization()(cx) x2=add([x2,cnh(x2,64,1,1)])\n",
    "    y= Conv2D(3, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')(cx)\n",
    "    return y\n",
    " \n",
    " \n",
    "from classifiers.ResNet import ResNet18   \n",
    " \n",
    "def rw(input_tensor, features ):\n",
    "    x = Conv2D(features, 3, activation='relu', padding='same', kernel_initializer='he_normal')(input_tensor)\n",
    "    x = Conv2D(features, 3, padding='same')(x)\n",
    "    return add([input_tensor, x])    \n",
    "\n",
    "\n",
    "def mdsr2(ix,f):\n",
    "    x=Conv2D(f, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')(ix)\n",
    "    y=actc(ix)\n",
    "    x1=rw(x,f)\n",
    "    x1=rw(x1,f)\n",
    "    x2=rw(x,f)\n",
    "    x2=rw(x2,f)\n",
    "    x3=rw(x,f)\n",
    "    x3=rw(x3,f)\n",
    "    x=add([x1,x2,x3])\n",
    "    x=Conv2D(3, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')(x)\n",
    "    x=add([x,y ])\n",
    "    return x  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model using train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 1e-4\n",
    "# num_classes = 1\n",
    "# resnet18 = ResNet18(input_shape=(di, di, 1), classes=num_classes, weight_decay=weight_decay)    \n",
    "\n",
    "input_im = Input(shape=(di, di, 1))\n",
    "#input_img=Lambda(lambda x:3*x**2-2*x**3)(input_im) \n",
    "\n",
    "x1=cnh(input_im,64,9,4) \n",
    "x1=actc(x1) \n",
    "y1=unt2(x1,3)\n",
    "x2=cnh(x1,64,9,1) \n",
    "x2=mdsr2(x2,10)\n",
    "x2=concatenate([y1,x2], axis = 3)\n",
    "p2 = MaxPooling2D(pool_size=(1, 1))(x2)\n",
    "p2 = Activation('relu')(p2)\n",
    "y= Conv2D(1, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')(p2) \n",
    " \n",
    "  \n",
    "# model = Model(input_im, y)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    " \n",
    " \n",
    " \n",
    "  \n",
    "model = Model(input_im, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 64)   5248        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 64, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 64, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 64)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 64, 64, 64)   0           activation_2[0][0]               \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 64, 64, 64)   0           activation_4[0][0]               \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 5)    2885        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 5)    2885        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 5)    2885        lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 15)   0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 3)    408         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 3)    84          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 3)    84          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 3)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 6)    168         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 6)    330         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 6)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 12)   660         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 12)   1308        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 12)     0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 24)     2616        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 24)     5208        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 64)   15616       conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8, 8, 24)     0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 10)   5770        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 24)     0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 64, 64, 10)   910         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 64, 10)   910         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 64, 64, 10)   910         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 4, 4, 48)     10416       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 64, 64, 10)   910         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 10)   910         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 64, 64, 10)   910         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 4, 4, 48)     20784       conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 64, 10)   0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, 64, 10)   0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 64, 64, 10)   0           conv2d_20[0][0]                  \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 64)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 4, 48)     0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 64, 64, 10)   910         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 64, 64, 10)   910         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 64, 64, 10)   910         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 64)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 64)   0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 3)    84          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 3)    84          max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 64, 64, 3)    165         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 3)    327         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 3)    1299        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 64, 64, 10)   910         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 64, 64, 10)   910         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 64, 64, 10)   910         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 64)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 64, 64, 64)   0           activation_6[0][0]               \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 64, 64, 64)   0           activation_8[0][0]               \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 15)   0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, 64, 10)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, 64, 10)   0           add_4[0][0]                      \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 64, 64, 10)   0           add_6[0][0]                      \n",
      "                                                                 conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 5)    2885        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 5)    2885        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 5)    2885        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 3)    408         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 64, 64, 3)    12          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 64, 64, 10)   0           add_3[0][0]                      \n",
      "                                                                 add_5[0][0]                      \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 64, 15)   0           conv2d_21[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 3)    0           conv2d_16[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 64, 64, 3)    273         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 64, 64, 3)    408         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 3)    84          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 64, 64, 3)    0           conv2d_37[0][0]                  \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 6)    0           conv2d_18[0][0]                  \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 6)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 64, 6)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 64, 64, 1)    55          activation_9[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 100,129\n",
      "Trainable params: 100,129\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    " \n",
    "\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from skimage.transform import rotate \n",
    "def augment_data(list_data, label, n): \n",
    "    augmented_data = list() \n",
    "    data_label = list()\n",
    "    for i in range(0, len(list_data)):\n",
    "        for j in range(0, n):\n",
    "            angle = np.random.randint(0, 90)\n",
    "            e_img = list_data[i]\n",
    "            e_img = normalize(e_img)\n",
    "            d_label = label[i]\n",
    "            if np.random.uniform()<0.5:\n",
    "                a_img = rotate(e_img, angle)\n",
    "            else:\n",
    "                a_img = rotate(e_img, -angle)\n",
    "            a_img = np.reshape(a_img, (a_img.shape[0], a_img.shape[1], 1))\n",
    "            augmented_data.append(a_img)\n",
    "            data_label.append(d_label)\n",
    "        \n",
    "    return augmented_data, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/1A work/jupyter/udac/LIVDET WORK/digitalfit/train ['fake', 'real']\n"
     ]
    }
   ],
   "source": [
    " \n",
    "(img_width, img_height) = (di, di)\n",
    "\n",
    "\n",
    "def load_imgages_from_folder(folder):\n",
    "    (images, labels, names, id) = ([], [], {}, 0)\n",
    "    for (subdirs, dirs, files) in os.walk(folder):\n",
    "        print(subdirs, dirs)\n",
    "        for subdir in dirs:\n",
    "            names[id] = subdir\n",
    "            subjectpath = os.path.join(folder, subdir)\n",
    "            for filename in os.listdir(subjectpath):\n",
    "                path = subjectpath + '/' + filename\n",
    "                label = id\n",
    "                img = cv2.imread(path, 0)\n",
    "                img = cv2.resize(img, (img_width, img_height))\n",
    "#                 img = img /255\n",
    "#                 img= np.reshape(img, (img.shape[0], img.shape[1], 1))\n",
    "                images.append(img)\n",
    "                labels.append(int(label))\n",
    "\n",
    "            id += 1\n",
    "#         print(names)\n",
    "#         print(labels)\n",
    "        return images, labels, names\n",
    "\n",
    "\n",
    "X, Y, Classes = load_imgages_from_folder(\"D:/1A work/jupyter/udac/LIVDET WORK/digitalfit/train\")\n",
    "x_train_aug, x_train_label = augment_data(X, Y, 12)\n",
    "\n",
    "X_train_aug, X_test_aug, X_train_aug_label, X_test_aug_label = train_test_split(x_train_aug, \n",
    "                                                                x_train_label, test_size=0.15, random_state=42) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "od=64\n",
    "fl=np.zeros(shape=(od,od, 1))\n",
    "rl=np.ones(shape=(od,od, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train_aug_label)):\n",
    "    t=X_train_aug_label[i]\n",
    "    if t>=1:\n",
    "          X_train_aug_label[i]=rl\n",
    "    else:\n",
    "         X_train_aug_label[i]=fl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_test_aug_label)):\n",
    "    t=X_test_aug_label[i]\n",
    "    if t>=1:\n",
    "          X_test_aug_label[i]=rl\n",
    "    else:\n",
    "         X_test_aug_label[i]=fl  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "X_train_aug = np.asarray(X_train_aug)\n",
    "X_test_aug = np.asarray(X_test_aug)\n",
    "\n",
    "train_aug_label = np.asarray(X_train_aug_label)\n",
    "test_aug_label = np.asarray(X_test_aug_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(test_aug_label)) :\n",
    "#     d=test_aug_label[i]\n",
    "#     s=np.sum(d)\n",
    "#     print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_aug_label[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20400 samples, validate on 3600 samples\n",
      "Epoch 1/760\n",
      "20400/20400 [==============================] - 66s 3ms/step - loss: 0.2724 - accuracy: 0.5255 - val_loss: 0.2525 - val_accuracy: 0.5810\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25245, saving model to B_digitalrs.hdf5\n",
      "Epoch 2/760\n",
      "20400/20400 [==============================] - 61s 3ms/step - loss: 0.2349 - accuracy: 0.6269 - val_loss: 0.2046 - val_accuracy: 0.7041\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25245 to 0.20456, saving model to B_digitalrs.hdf5\n",
      "Epoch 3/760\n",
      "20400/20400 [==============================] - 62s 3ms/step - loss: 0.1873 - accuracy: 0.7353 - val_loss: 0.1944 - val_accuracy: 0.7149\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.20456 to 0.19439, saving model to B_digitalrs.hdf5\n",
      "Epoch 4/760\n",
      "20400/20400 [==============================] - 62s 3ms/step - loss: 0.1619 - accuracy: 0.7809 - val_loss: 0.1486 - val_accuracy: 0.8045\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.19439 to 0.14855, saving model to B_digitalrs.hdf5\n",
      "Epoch 5/760\n",
      "20400/20400 [==============================] - 61s 3ms/step - loss: 0.1463 - accuracy: 0.8043 - val_loss: 0.1581 - val_accuracy: 0.7800\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.14855\n",
      "Epoch 6/760\n",
      "20400/20400 [==============================] - 61s 3ms/step - loss: 0.1361 - accuracy: 0.8194 - val_loss: 0.1242 - val_accuracy: 0.8383\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.14855 to 0.12425, saving model to B_digitalrs.hdf5\n",
      "Epoch 7/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.1287 - accuracy: 0.8305 - val_loss: 0.1203 - val_accuracy: 0.8424\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.12425 to 0.12034, saving model to B_digitalrs.hdf5\n",
      "Epoch 8/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.1213 - accuracy: 0.8416 - val_loss: 0.1150 - val_accuracy: 0.8523\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.12034 to 0.11495, saving model to B_digitalrs.hdf5\n",
      "Epoch 9/760\n",
      "20400/20400 [==============================] - 61s 3ms/step - loss: 0.1178 - accuracy: 0.8462 - val_loss: 0.1098 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11495 to 0.10982, saving model to B_digitalrs.hdf5\n",
      "Epoch 10/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.1152 - accuracy: 0.8501 - val_loss: 0.1064 - val_accuracy: 0.8636\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.10982 to 0.10641, saving model to B_digitalrs.hdf5\n",
      "Epoch 11/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.1145 - accuracy: 0.8509 - val_loss: 0.1070 - val_accuracy: 0.8674\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.10641\n",
      "Epoch 12/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.1118 - accuracy: 0.8551 - val_loss: 0.1104 - val_accuracy: 0.8559\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.10641\n",
      "Epoch 13/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.1081 - accuracy: 0.8601 - val_loss: 0.0989 - val_accuracy: 0.8736\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.10641 to 0.09887, saving model to B_digitalrs.hdf5\n",
      "Epoch 14/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.1065 - accuracy: 0.8624 - val_loss: 0.1189 - val_accuracy: 0.8386\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.09887\n",
      "Epoch 15/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.1032 - accuracy: 0.8666 - val_loss: 0.0971 - val_accuracy: 0.8744\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.09887 to 0.09712, saving model to B_digitalrs.hdf5\n",
      "Epoch 16/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.1062 - accuracy: 0.8623 - val_loss: 0.1025 - val_accuracy: 0.8680\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.09712\n",
      "Epoch 17/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0999 - accuracy: 0.8711 - val_loss: 0.1289 - val_accuracy: 0.8248\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.09712\n",
      "Epoch 18/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.1007 - accuracy: 0.8698 - val_loss: 0.0968 - val_accuracy: 0.8744\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.09712 to 0.09679, saving model to B_digitalrs.hdf5\n",
      "Epoch 19/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0971 - accuracy: 0.8751 - val_loss: 0.0992 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.09679\n",
      "Epoch 20/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0968 - accuracy: 0.8759 - val_loss: 0.0900 - val_accuracy: 0.8855\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.09679 to 0.08997, saving model to B_digitalrs.hdf5\n",
      "Epoch 21/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0953 - accuracy: 0.8777 - val_loss: 0.0960 - val_accuracy: 0.8776\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.08997\n",
      "Epoch 22/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0964 - accuracy: 0.8760 - val_loss: 0.0928 - val_accuracy: 0.8822\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.08997\n",
      "Epoch 23/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0945 - accuracy: 0.8785 - val_loss: 0.0893 - val_accuracy: 0.8854\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.08997 to 0.08932, saving model to B_digitalrs.hdf5\n",
      "Epoch 24/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0936 - accuracy: 0.8800 - val_loss: 0.0913 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.08932\n",
      "Epoch 25/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0916 - accuracy: 0.8832 - val_loss: 0.0875 - val_accuracy: 0.8887\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.08932 to 0.08748, saving model to B_digitalrs.hdf5\n",
      "Epoch 26/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0925 - accuracy: 0.8819 - val_loss: 0.0861 - val_accuracy: 0.8907\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.08748 to 0.08611, saving model to B_digitalrs.hdf5\n",
      "Epoch 27/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0883 - accuracy: 0.8885 - val_loss: 0.0824 - val_accuracy: 0.8966\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.08611 to 0.08242, saving model to B_digitalrs.hdf5\n",
      "Epoch 28/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0883 - accuracy: 0.8890 - val_loss: 0.0856 - val_accuracy: 0.8943\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.08242\n",
      "Epoch 29/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0870 - accuracy: 0.8911 - val_loss: 0.0817 - val_accuracy: 0.8981\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.08242 to 0.08168, saving model to B_digitalrs.hdf5\n",
      "Epoch 30/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0842 - accuracy: 0.8952 - val_loss: 0.0864 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.08168\n",
      "Epoch 31/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0833 - accuracy: 0.8971 - val_loss: 0.0782 - val_accuracy: 0.9036\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.08168 to 0.07822, saving model to B_digitalrs.hdf5\n",
      "Epoch 32/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0825 - accuracy: 0.8984 - val_loss: 0.0868 - val_accuracy: 0.8905\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.07822\n",
      "Epoch 33/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0795 - accuracy: 0.9029 - val_loss: 0.0754 - val_accuracy: 0.9087\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.07822 to 0.07542, saving model to B_digitalrs.hdf5\n",
      "Epoch 34/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0797 - accuracy: 0.9026 - val_loss: 0.0801 - val_accuracy: 0.9043\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.07542\n",
      "Epoch 35/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0786 - accuracy: 0.9045 - val_loss: 0.0777 - val_accuracy: 0.9056\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.07542\n",
      "Epoch 36/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0784 - accuracy: 0.9047 - val_loss: 0.0813 - val_accuracy: 0.9002\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.07542\n",
      "Epoch 37/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0770 - accuracy: 0.9065 - val_loss: 0.0937 - val_accuracy: 0.8814\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.07542\n",
      "Epoch 38/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0754 - accuracy: 0.9092 - val_loss: 0.0812 - val_accuracy: 0.8999\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07542\n",
      "Epoch 39/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0758 - accuracy: 0.9081 - val_loss: 0.0705 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.07542 to 0.07053, saving model to B_digitalrs.hdf5\n",
      "Epoch 40/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0743 - accuracy: 0.9104 - val_loss: 0.0748 - val_accuracy: 0.9082\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.07053\n",
      "Epoch 41/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0740 - accuracy: 0.9107 - val_loss: 0.0856 - val_accuracy: 0.8933\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.07053\n",
      "Epoch 42/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0753 - accuracy: 0.9093 - val_loss: 0.0803 - val_accuracy: 0.9010\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.07053\n",
      "Epoch 43/760\n",
      "20400/20400 [==============================] - 61s 3ms/step - loss: 0.0740 - accuracy: 0.9108 - val_loss: 0.0807 - val_accuracy: 0.9010\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.07053\n",
      "Epoch 44/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0720 - accuracy: 0.9135 - val_loss: 0.0706 - val_accuracy: 0.9150\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.07053\n",
      "Epoch 45/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0730 - accuracy: 0.9123 - val_loss: 0.0708 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.07053\n",
      "Epoch 46/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0712 - accuracy: 0.9144 - val_loss: 0.0710 - val_accuracy: 0.9139\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.07053\n",
      "Epoch 47/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0715 - accuracy: 0.9140 - val_loss: 0.0678 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.07053 to 0.06779, saving model to B_digitalrs.hdf5\n",
      "Epoch 48/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0709 - accuracy: 0.9148 - val_loss: 0.0704 - val_accuracy: 0.9144\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.06779\n",
      "Epoch 49/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0722 - accuracy: 0.9131 - val_loss: 0.0718 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.06779\n",
      "Epoch 50/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0698 - accuracy: 0.9168 - val_loss: 0.0731 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.06779\n",
      "Epoch 51/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0710 - accuracy: 0.9148 - val_loss: 0.0820 - val_accuracy: 0.8955\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.06779\n",
      "Epoch 52/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0704 - accuracy: 0.9158 - val_loss: 0.0718 - val_accuracy: 0.9142\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.06779\n",
      "Epoch 53/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0690 - accuracy: 0.9175 - val_loss: 0.0701 - val_accuracy: 0.9151\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.06779\n",
      "Epoch 54/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0702 - accuracy: 0.9159 - val_loss: 0.0736 - val_accuracy: 0.9108\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.06779\n",
      "Epoch 55/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0688 - accuracy: 0.9178 - val_loss: 0.0770 - val_accuracy: 0.9067\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.06779\n",
      "Epoch 56/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0697 - accuracy: 0.9165 - val_loss: 0.0709 - val_accuracy: 0.9141\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.06779\n",
      "Epoch 57/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0688 - accuracy: 0.9178 - val_loss: 0.0670 - val_accuracy: 0.9211\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.06779 to 0.06702, saving model to B_digitalrs.hdf5\n",
      "Epoch 58/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0688 - accuracy: 0.9180 - val_loss: 0.0802 - val_accuracy: 0.8986\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.06702\n",
      "Epoch 59/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0697 - accuracy: 0.9163 - val_loss: 0.0896 - val_accuracy: 0.8846\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.06702\n",
      "Epoch 60/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0679 - accuracy: 0.9192 - val_loss: 0.0649 - val_accuracy: 0.9228\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.06702 to 0.06485, saving model to B_digitalrs.hdf5\n",
      "Epoch 61/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0678 - accuracy: 0.9191 - val_loss: 0.0905 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.06485\n",
      "Epoch 62/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0662 - accuracy: 0.9212 - val_loss: 0.0678 - val_accuracy: 0.9171\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.06485\n",
      "Epoch 63/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0684 - accuracy: 0.9181 - val_loss: 0.0697 - val_accuracy: 0.9155\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.06485\n",
      "Epoch 64/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0678 - accuracy: 0.9189 - val_loss: 0.0695 - val_accuracy: 0.9170\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.06485\n",
      "Epoch 65/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0662 - accuracy: 0.9213 - val_loss: 0.0646 - val_accuracy: 0.9225\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.06485 to 0.06464, saving model to B_digitalrs.hdf5\n",
      "Epoch 66/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0669 - accuracy: 0.9203 - val_loss: 0.0702 - val_accuracy: 0.9154\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.06464\n",
      "Epoch 67/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0672 - accuracy: 0.9197 - val_loss: 0.0697 - val_accuracy: 0.9165\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.06464\n",
      "Epoch 68/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0653 - accuracy: 0.9223 - val_loss: 0.0634 - val_accuracy: 0.9257\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.06464 to 0.06337, saving model to B_digitalrs.hdf5\n",
      "Epoch 69/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0665 - accuracy: 0.9206 - val_loss: 0.0678 - val_accuracy: 0.9184\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.06337\n",
      "Epoch 70/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0663 - accuracy: 0.9209 - val_loss: 0.0646 - val_accuracy: 0.9229\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.06337\n",
      "Epoch 71/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0650 - accuracy: 0.9226 - val_loss: 0.0657 - val_accuracy: 0.9214\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.06337\n",
      "Epoch 72/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0653 - accuracy: 0.9224 - val_loss: 0.0654 - val_accuracy: 0.9223\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.06337\n",
      "Epoch 73/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0631 - accuracy: 0.9253 - val_loss: 0.0637 - val_accuracy: 0.9246\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.06337\n",
      "Epoch 74/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0671 - accuracy: 0.9198 - val_loss: 0.0662 - val_accuracy: 0.9209\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.06337\n",
      "Epoch 75/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0650 - accuracy: 0.9228 - val_loss: 0.0723 - val_accuracy: 0.9136\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.06337\n",
      "Epoch 76/760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0659 - accuracy: 0.9214 - val_loss: 0.0638 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.06337\n",
      "Epoch 77/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0640 - accuracy: 0.9242 - val_loss: 0.0663 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.06337\n",
      "Epoch 78/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0629 - accuracy: 0.9255 - val_loss: 0.0674 - val_accuracy: 0.9189\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.06337\n",
      "Epoch 79/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0634 - accuracy: 0.9250 - val_loss: 0.0702 - val_accuracy: 0.9122\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.06337\n",
      "Epoch 80/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0629 - accuracy: 0.9254 - val_loss: 0.0742 - val_accuracy: 0.9068\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.06337\n",
      "Epoch 81/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0628 - accuracy: 0.9257 - val_loss: 0.0737 - val_accuracy: 0.9148\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.06337\n",
      "Epoch 82/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0645 - accuracy: 0.9232 - val_loss: 0.0641 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.06337\n",
      "Epoch 83/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0616 - accuracy: 0.9274 - val_loss: 0.0638 - val_accuracy: 0.9239\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.06337\n",
      "Epoch 84/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0629 - accuracy: 0.9255 - val_loss: 0.0648 - val_accuracy: 0.9252\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.06337\n",
      "Epoch 85/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0639 - accuracy: 0.9240 - val_loss: 0.0695 - val_accuracy: 0.9152\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.06337\n",
      "Epoch 86/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0625 - accuracy: 0.9259 - val_loss: 0.0622 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.06337 to 0.06223, saving model to B_digitalrs.hdf5\n",
      "Epoch 87/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0607 - accuracy: 0.9284 - val_loss: 0.0651 - val_accuracy: 0.9201\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.06223\n",
      "Epoch 88/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0619 - accuracy: 0.9268 - val_loss: 0.0651 - val_accuracy: 0.9217\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.06223\n",
      "Epoch 89/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0628 - accuracy: 0.9255 - val_loss: 0.0661 - val_accuracy: 0.9218\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.06223\n",
      "Epoch 90/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0611 - accuracy: 0.9276 - val_loss: 0.0667 - val_accuracy: 0.9187\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.06223\n",
      "Epoch 91/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0631 - accuracy: 0.9247 - val_loss: 0.0810 - val_accuracy: 0.9014\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.06223\n",
      "Epoch 92/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0607 - accuracy: 0.9285 - val_loss: 0.0633 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.06223\n",
      "Epoch 93/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0642 - accuracy: 0.9233 - val_loss: 0.0627 - val_accuracy: 0.9248\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.06223\n",
      "Epoch 94/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0601 - accuracy: 0.9291 - val_loss: 0.0653 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.06223\n",
      "Epoch 95/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0603 - accuracy: 0.9288 - val_loss: 0.0609 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.06223 to 0.06088, saving model to B_digitalrs.hdf5\n",
      "Epoch 96/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0603 - accuracy: 0.9286 - val_loss: 0.0696 - val_accuracy: 0.9137\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.06088\n",
      "Epoch 97/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0609 - accuracy: 0.9278 - val_loss: 0.0696 - val_accuracy: 0.9160\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.06088\n",
      "Epoch 98/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0595 - accuracy: 0.9297 - val_loss: 0.0618 - val_accuracy: 0.9254\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.06088\n",
      "Epoch 99/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0610 - accuracy: 0.9277 - val_loss: 0.0603 - val_accuracy: 0.9276\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.06088 to 0.06033, saving model to B_digitalrs.hdf5\n",
      "Epoch 100/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0584 - accuracy: 0.9313 - val_loss: 0.0642 - val_accuracy: 0.9241\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.06033\n",
      "Epoch 101/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0607 - accuracy: 0.9280 - val_loss: 0.0666 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.06033\n",
      "Epoch 102/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0598 - accuracy: 0.9292 - val_loss: 0.0620 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.06033\n",
      "Epoch 103/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0586 - accuracy: 0.9306 - val_loss: 0.0588 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.06033 to 0.05883, saving model to B_digitalrs.hdf5\n",
      "Epoch 104/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0610 - accuracy: 0.9275 - val_loss: 0.0625 - val_accuracy: 0.9244\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.05883\n",
      "Epoch 105/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0583 - accuracy: 0.9311 - val_loss: 0.0653 - val_accuracy: 0.9212\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.05883\n",
      "Epoch 106/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0584 - accuracy: 0.9312 - val_loss: 0.0654 - val_accuracy: 0.9202\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.05883\n",
      "Epoch 107/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0609 - accuracy: 0.9276 - val_loss: 0.0782 - val_accuracy: 0.9000\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.05883\n",
      "Epoch 108/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0596 - accuracy: 0.9295 - val_loss: 0.0653 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.05883\n",
      "Epoch 109/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0586 - accuracy: 0.9306 - val_loss: 0.0730 - val_accuracy: 0.9097\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.05883\n",
      "Epoch 110/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0587 - accuracy: 0.9306 - val_loss: 0.0600 - val_accuracy: 0.9288\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.05883\n",
      "Epoch 111/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0583 - accuracy: 0.9311 - val_loss: 0.0588 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.05883 to 0.05877, saving model to B_digitalrs.hdf5\n",
      "Epoch 112/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0588 - accuracy: 0.9305 - val_loss: 0.0629 - val_accuracy: 0.9233\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.05877\n",
      "Epoch 113/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0579 - accuracy: 0.9318 - val_loss: 0.0600 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.05877\n",
      "Epoch 114/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0580 - accuracy: 0.9316 - val_loss: 0.0661 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.05877\n",
      "Epoch 115/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0586 - accuracy: 0.9308 - val_loss: 0.0604 - val_accuracy: 0.9282\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.05877\n",
      "Epoch 116/760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0587 - accuracy: 0.9305 - val_loss: 0.0658 - val_accuracy: 0.9207\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.05877\n",
      "Epoch 117/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0572 - accuracy: 0.9325 - val_loss: 0.0579 - val_accuracy: 0.9316\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.05877 to 0.05786, saving model to B_digitalrs.hdf5\n",
      "Epoch 118/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0555 - accuracy: 0.9349 - val_loss: 0.0611 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.05786\n",
      "Epoch 119/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0566 - accuracy: 0.9333 - val_loss: 0.0669 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.05786\n",
      "Epoch 120/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0588 - accuracy: 0.9301 - val_loss: 0.0608 - val_accuracy: 0.9273\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.05786\n",
      "Epoch 121/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0568 - accuracy: 0.9328 - val_loss: 0.0641 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.05786\n",
      "Epoch 122/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0562 - accuracy: 0.9337 - val_loss: 0.0627 - val_accuracy: 0.9234\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.05786\n",
      "Epoch 123/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0575 - accuracy: 0.9321 - val_loss: 0.0586 - val_accuracy: 0.9309\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.05786\n",
      "Epoch 124/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0581 - accuracy: 0.9312 - val_loss: 0.0606 - val_accuracy: 0.9274\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 0.05786\n",
      "Epoch 125/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0569 - accuracy: 0.9326 - val_loss: 0.0587 - val_accuracy: 0.9295\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.05786\n",
      "Epoch 126/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0552 - accuracy: 0.9350 - val_loss: 0.0600 - val_accuracy: 0.9283\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.05786\n",
      "Epoch 127/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0597 - accuracy: 0.9291 - val_loss: 0.0581 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.05786\n",
      "Epoch 128/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0547 - accuracy: 0.9357 - val_loss: 0.0581 - val_accuracy: 0.9307\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.05786\n",
      "Epoch 129/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0561 - accuracy: 0.9340 - val_loss: 0.0604 - val_accuracy: 0.9287\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.05786\n",
      "Epoch 130/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0558 - accuracy: 0.9341 - val_loss: 0.0571 - val_accuracy: 0.9315\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.05786 to 0.05707, saving model to B_digitalrs.hdf5\n",
      "Epoch 131/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0567 - accuracy: 0.9329 - val_loss: 0.0607 - val_accuracy: 0.9260\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.05707\n",
      "Epoch 132/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0572 - accuracy: 0.9322 - val_loss: 0.0708 - val_accuracy: 0.9127\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.05707\n",
      "Epoch 133/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0559 - accuracy: 0.9339 - val_loss: 0.0631 - val_accuracy: 0.9231\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.05707\n",
      "Epoch 134/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0578 - accuracy: 0.9314 - val_loss: 0.0606 - val_accuracy: 0.9278\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.05707\n",
      "Epoch 135/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0555 - accuracy: 0.9347 - val_loss: 0.0856 - val_accuracy: 0.8920\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.05707\n",
      "Epoch 136/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0543 - accuracy: 0.9361 - val_loss: 0.0601 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.05707\n",
      "Epoch 137/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0550 - accuracy: 0.9352 - val_loss: 0.0585 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.05707\n",
      "Epoch 138/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0552 - accuracy: 0.9348 - val_loss: 0.0846 - val_accuracy: 0.8950\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.05707\n",
      "Epoch 139/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0562 - accuracy: 0.9335 - val_loss: 0.0553 - val_accuracy: 0.9348\n",
      "\n",
      "Epoch 00139: val_loss improved from 0.05707 to 0.05532, saving model to B_digitalrs.hdf5\n",
      "Epoch 140/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0548 - accuracy: 0.9353 - val_loss: 0.0543 - val_accuracy: 0.9356\n",
      "\n",
      "Epoch 00140: val_loss improved from 0.05532 to 0.05434, saving model to B_digitalrs.hdf5\n",
      "Epoch 141/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0554 - accuracy: 0.9348 - val_loss: 0.0669 - val_accuracy: 0.9195\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.05434\n",
      "Epoch 142/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0553 - accuracy: 0.9349 - val_loss: 0.0599 - val_accuracy: 0.9272\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.05434\n",
      "Epoch 143/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0551 - accuracy: 0.9349 - val_loss: 0.0643 - val_accuracy: 0.9222\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.05434\n",
      "Epoch 144/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0556 - accuracy: 0.9344 - val_loss: 0.0714 - val_accuracy: 0.9134\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.05434\n",
      "Epoch 145/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0539 - accuracy: 0.9364 - val_loss: 0.0560 - val_accuracy: 0.9341\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.05434\n",
      "Epoch 146/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0553 - accuracy: 0.9346 - val_loss: 0.0626 - val_accuracy: 0.9235\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.05434\n",
      "Epoch 147/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0534 - accuracy: 0.9371 - val_loss: 0.0564 - val_accuracy: 0.9331\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.05434\n",
      "Epoch 148/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0540 - accuracy: 0.9365 - val_loss: 0.0561 - val_accuracy: 0.9336\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.05434\n",
      "Epoch 149/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0543 - accuracy: 0.9357 - val_loss: 0.0575 - val_accuracy: 0.9305\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.05434\n",
      "Epoch 150/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0540 - accuracy: 0.9364 - val_loss: 0.0593 - val_accuracy: 0.9291\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.05434\n",
      "Epoch 151/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0537 - accuracy: 0.9366 - val_loss: 0.0551 - val_accuracy: 0.9350\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.05434\n",
      "Epoch 152/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0524 - accuracy: 0.9385 - val_loss: 0.0632 - val_accuracy: 0.9251\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.05434\n",
      "Epoch 153/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0538 - accuracy: 0.9365 - val_loss: 0.0565 - val_accuracy: 0.9320\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.05434\n",
      "Epoch 154/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0529 - accuracy: 0.9378 - val_loss: 0.0535 - val_accuracy: 0.9365\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.05434 to 0.05353, saving model to B_digitalrs.hdf5\n",
      "Epoch 155/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0524 - accuracy: 0.9384 - val_loss: 0.0547 - val_accuracy: 0.9350\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.05353\n",
      "Epoch 156/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0533 - accuracy: 0.9371 - val_loss: 0.0637 - val_accuracy: 0.9242\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.05353\n",
      "Epoch 157/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0534 - accuracy: 0.9371 - val_loss: 0.0545 - val_accuracy: 0.9358\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.05353\n",
      "Epoch 158/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0522 - accuracy: 0.9385 - val_loss: 0.0531 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00158: val_loss improved from 0.05353 to 0.05309, saving model to B_digitalrs.hdf5\n",
      "Epoch 159/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0537 - accuracy: 0.9367 - val_loss: 0.0554 - val_accuracy: 0.9334\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.05309\n",
      "Epoch 160/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0528 - accuracy: 0.9378 - val_loss: 0.0533 - val_accuracy: 0.9373\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.05309\n",
      "Epoch 161/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0522 - accuracy: 0.9385 - val_loss: 0.0566 - val_accuracy: 0.9324\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.05309\n",
      "Epoch 162/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0509 - accuracy: 0.9402 - val_loss: 0.0555 - val_accuracy: 0.9336\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 0.05309\n",
      "Epoch 163/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0546 - accuracy: 0.9355 - val_loss: 0.0545 - val_accuracy: 0.9350\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.05309\n",
      "Epoch 164/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0520 - accuracy: 0.9388 - val_loss: 0.0550 - val_accuracy: 0.9348\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.05309\n",
      "Epoch 165/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0523 - accuracy: 0.9384 - val_loss: 0.0539 - val_accuracy: 0.9359\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.05309\n",
      "Epoch 166/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0523 - accuracy: 0.9384 - val_loss: 0.0586 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.05309\n",
      "Epoch 167/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0524 - accuracy: 0.9381 - val_loss: 0.0548 - val_accuracy: 0.9343\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.05309\n",
      "Epoch 168/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0524 - accuracy: 0.9382 - val_loss: 0.0605 - val_accuracy: 0.9285\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.05309\n",
      "Epoch 169/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0517 - accuracy: 0.9393 - val_loss: 0.0578 - val_accuracy: 0.9310\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.05309\n",
      "Epoch 170/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0513 - accuracy: 0.9398 - val_loss: 0.0574 - val_accuracy: 0.9311\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.05309\n",
      "Epoch 171/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0505 - accuracy: 0.9407 - val_loss: 0.0533 - val_accuracy: 0.9363\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.05309\n",
      "Epoch 172/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0513 - accuracy: 0.9397 - val_loss: 0.0561 - val_accuracy: 0.9332\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.05309\n",
      "Epoch 173/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0516 - accuracy: 0.9396 - val_loss: 0.0516 - val_accuracy: 0.9390\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.05309 to 0.05159, saving model to B_digitalrs.hdf5\n",
      "Epoch 174/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0522 - accuracy: 0.9386 - val_loss: 0.0534 - val_accuracy: 0.9372\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.05159\n",
      "Epoch 175/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0525 - accuracy: 0.9382 - val_loss: 0.0561 - val_accuracy: 0.9330\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.05159\n",
      "Epoch 176/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0512 - accuracy: 0.9397 - val_loss: 0.0584 - val_accuracy: 0.9303\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.05159\n",
      "Epoch 177/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0514 - accuracy: 0.9396 - val_loss: 0.0539 - val_accuracy: 0.9357\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.05159\n",
      "Epoch 178/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0514 - accuracy: 0.9396 - val_loss: 0.0521 - val_accuracy: 0.9384\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.05159\n",
      "Epoch 179/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0509 - accuracy: 0.9401 - val_loss: 0.0848 - val_accuracy: 0.8993\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.05159\n",
      "Epoch 180/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0535 - accuracy: 0.9370 - val_loss: 0.0537 - val_accuracy: 0.9362\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.05159\n",
      "Epoch 181/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0512 - accuracy: 0.9399 - val_loss: 0.0568 - val_accuracy: 0.9317\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.05159\n",
      "Epoch 182/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0510 - accuracy: 0.9400 - val_loss: 0.0515 - val_accuracy: 0.9393\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.05159 to 0.05146, saving model to B_digitalrs.hdf5\n",
      "Epoch 183/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0508 - accuracy: 0.9406 - val_loss: 0.0515 - val_accuracy: 0.9388\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.05146\n",
      "Epoch 184/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0508 - accuracy: 0.9404 - val_loss: 0.0541 - val_accuracy: 0.9365\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.05146\n",
      "Epoch 185/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0501 - accuracy: 0.9413 - val_loss: 0.0561 - val_accuracy: 0.9321\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.05146\n",
      "Epoch 186/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0502 - accuracy: 0.9415 - val_loss: 0.0540 - val_accuracy: 0.9356\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.05146\n",
      "Epoch 187/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0517 - accuracy: 0.9391 - val_loss: 0.0541 - val_accuracy: 0.9361\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.05146\n",
      "Epoch 188/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0502 - accuracy: 0.9411 - val_loss: 0.0574 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.05146\n",
      "Epoch 189/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0495 - accuracy: 0.9423 - val_loss: 0.0533 - val_accuracy: 0.9369\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.05146\n",
      "Epoch 190/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0493 - accuracy: 0.9423 - val_loss: 0.0526 - val_accuracy: 0.9379\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.05146\n",
      "Epoch 191/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0508 - accuracy: 0.9402 - val_loss: 0.0535 - val_accuracy: 0.9361\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.05146\n",
      "Epoch 192/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0504 - accuracy: 0.9410 - val_loss: 0.0549 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 0.05146\n",
      "Epoch 193/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0498 - accuracy: 0.9417 - val_loss: 0.0540 - val_accuracy: 0.9349\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.05146\n",
      "Epoch 194/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0519 - accuracy: 0.9391 - val_loss: 0.0519 - val_accuracy: 0.9383\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.05146\n",
      "Epoch 195/760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0501 - accuracy: 0.9415 - val_loss: 0.0648 - val_accuracy: 0.9200\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.05146\n",
      "Epoch 196/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0494 - accuracy: 0.9422 - val_loss: 0.0554 - val_accuracy: 0.9335\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.05146\n",
      "Epoch 197/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0522 - accuracy: 0.9386 - val_loss: 0.0626 - val_accuracy: 0.9250\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.05146\n",
      "Epoch 198/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0488 - accuracy: 0.9431 - val_loss: 0.0529 - val_accuracy: 0.9368\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.05146\n",
      "Epoch 199/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0487 - accuracy: 0.9429 - val_loss: 0.0551 - val_accuracy: 0.9336\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.05146\n",
      "Epoch 200/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0488 - accuracy: 0.9431 - val_loss: 0.0516 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.05146\n",
      "Epoch 201/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0517 - accuracy: 0.9392 - val_loss: 0.0567 - val_accuracy: 0.9313\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 0.05146\n",
      "Epoch 202/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0488 - accuracy: 0.9430 - val_loss: 0.0543 - val_accuracy: 0.9359\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 0.05146\n",
      "Epoch 203/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0505 - accuracy: 0.9408 - val_loss: 0.0526 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 0.05146\n",
      "Epoch 204/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0480 - accuracy: 0.9440 - val_loss: 0.0521 - val_accuracy: 0.9381\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 0.05146\n",
      "Epoch 205/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0484 - accuracy: 0.9435 - val_loss: 0.0590 - val_accuracy: 0.9293\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 0.05146\n",
      "Epoch 206/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0509 - accuracy: 0.9402 - val_loss: 0.0567 - val_accuracy: 0.9320\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 0.05146\n",
      "Epoch 207/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0477 - accuracy: 0.9443 - val_loss: 0.0539 - val_accuracy: 0.9360\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 0.05146\n",
      "Epoch 208/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0502 - accuracy: 0.9410 - val_loss: 0.0527 - val_accuracy: 0.9373\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 0.05146\n",
      "Epoch 209/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0498 - accuracy: 0.9417 - val_loss: 0.0540 - val_accuracy: 0.9353\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 0.05146\n",
      "Epoch 210/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0494 - accuracy: 0.9422 - val_loss: 0.0527 - val_accuracy: 0.9373\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 0.05146\n",
      "Epoch 211/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0479 - accuracy: 0.9441 - val_loss: 0.0498 - val_accuracy: 0.9414\n",
      "\n",
      "Epoch 00211: val_loss improved from 0.05146 to 0.04976, saving model to B_digitalrs.hdf5\n",
      "Epoch 212/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0516 - accuracy: 0.9393 - val_loss: 0.0537 - val_accuracy: 0.9357\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 0.04976\n",
      "Epoch 213/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0490 - accuracy: 0.9425 - val_loss: 0.0511 - val_accuracy: 0.9396\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 0.04976\n",
      "Epoch 214/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0493 - accuracy: 0.9422 - val_loss: 0.0726 - val_accuracy: 0.9104\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 0.04976\n",
      "Epoch 215/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0489 - accuracy: 0.9429 - val_loss: 0.0505 - val_accuracy: 0.9410\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 0.04976\n",
      "Epoch 216/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0488 - accuracy: 0.9429 - val_loss: 0.0493 - val_accuracy: 0.9416\n",
      "\n",
      "Epoch 00216: val_loss improved from 0.04976 to 0.04935, saving model to B_digitalrs.hdf5\n",
      "Epoch 217/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0479 - accuracy: 0.9442 - val_loss: 0.0502 - val_accuracy: 0.9404\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 0.04935\n",
      "Epoch 218/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0496 - accuracy: 0.9419 - val_loss: 0.0511 - val_accuracy: 0.9388\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 0.04935\n",
      "Epoch 219/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0482 - accuracy: 0.9437 - val_loss: 0.0517 - val_accuracy: 0.9389\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 0.04935\n",
      "Epoch 220/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0479 - accuracy: 0.9444 - val_loss: 0.0663 - val_accuracy: 0.9197\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 0.04935\n",
      "Epoch 221/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0490 - accuracy: 0.9428 - val_loss: 0.0579 - val_accuracy: 0.9314\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 0.04935\n",
      "Epoch 222/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0498 - accuracy: 0.9417 - val_loss: 0.0499 - val_accuracy: 0.9411\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 0.04935\n",
      "Epoch 223/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0481 - accuracy: 0.9439 - val_loss: 0.0501 - val_accuracy: 0.9411\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 0.04935\n",
      "Epoch 224/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0494 - accuracy: 0.9421 - val_loss: 0.0513 - val_accuracy: 0.9392\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 0.04935\n",
      "Epoch 225/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0482 - accuracy: 0.9439 - val_loss: 0.0550 - val_accuracy: 0.9337\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 0.04935\n",
      "Epoch 226/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0483 - accuracy: 0.9436 - val_loss: 0.0520 - val_accuracy: 0.9387\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 0.04935\n",
      "Epoch 227/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0469 - accuracy: 0.9454 - val_loss: 0.0542 - val_accuracy: 0.9352\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 0.04935\n",
      "Epoch 228/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0488 - accuracy: 0.9429 - val_loss: 0.0533 - val_accuracy: 0.9373\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 0.04935\n",
      "Epoch 229/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0474 - accuracy: 0.9447 - val_loss: 0.0511 - val_accuracy: 0.9390\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 0.04935\n",
      "Epoch 230/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0495 - accuracy: 0.9421 - val_loss: 0.0509 - val_accuracy: 0.9399\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 0.04935\n",
      "Epoch 231/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0473 - accuracy: 0.9449 - val_loss: 0.0533 - val_accuracy: 0.9373\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 0.04935\n",
      "Epoch 232/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0482 - accuracy: 0.9437 - val_loss: 0.0720 - val_accuracy: 0.9168\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 0.04935\n",
      "Epoch 233/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0480 - accuracy: 0.9441 - val_loss: 0.0530 - val_accuracy: 0.9368\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 0.04935\n",
      "Epoch 234/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0472 - accuracy: 0.9452 - val_loss: 0.0549 - val_accuracy: 0.9347\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 0.04935\n",
      "Epoch 235/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0489 - accuracy: 0.9430 - val_loss: 0.0533 - val_accuracy: 0.9366\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 0.04935\n",
      "Epoch 236/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0461 - accuracy: 0.9467 - val_loss: 0.0607 - val_accuracy: 0.9268\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 0.04935\n",
      "Epoch 237/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0488 - accuracy: 0.9430 - val_loss: 0.0492 - val_accuracy: 0.9424\n",
      "\n",
      "Epoch 00237: val_loss improved from 0.04935 to 0.04917, saving model to B_digitalrs.hdf5\n",
      "Epoch 238/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0468 - accuracy: 0.9456 - val_loss: 0.0520 - val_accuracy: 0.9383\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 0.04917\n",
      "Epoch 239/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0480 - accuracy: 0.9442 - val_loss: 0.0607 - val_accuracy: 0.9258\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 0.04917\n",
      "Epoch 240/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0483 - accuracy: 0.9437 - val_loss: 0.0662 - val_accuracy: 0.9181\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 0.04917\n",
      "Epoch 241/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0481 - accuracy: 0.9441 - val_loss: 0.0546 - val_accuracy: 0.9344\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 0.04917\n",
      "Epoch 242/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0464 - accuracy: 0.9463 - val_loss: 0.0490 - val_accuracy: 0.9420\n",
      "\n",
      "Epoch 00242: val_loss improved from 0.04917 to 0.04902, saving model to B_digitalrs.hdf5\n",
      "Epoch 243/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0467 - accuracy: 0.9457 - val_loss: 0.0531 - val_accuracy: 0.9366\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 0.04902\n",
      "Epoch 244/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0501 - accuracy: 0.9414 - val_loss: 0.0507 - val_accuracy: 0.9399\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 0.04902\n",
      "Epoch 245/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0475 - accuracy: 0.9447 - val_loss: 0.0510 - val_accuracy: 0.9396\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 0.04902\n",
      "Epoch 246/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0459 - accuracy: 0.9468 - val_loss: 0.0474 - val_accuracy: 0.9448\n",
      "\n",
      "Epoch 00246: val_loss improved from 0.04902 to 0.04745, saving model to B_digitalrs.hdf5\n",
      "Epoch 247/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0477 - accuracy: 0.9446 - val_loss: 0.0601 - val_accuracy: 0.9265\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 0.04745\n",
      "Epoch 248/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0464 - accuracy: 0.9462 - val_loss: 0.0720 - val_accuracy: 0.9119\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 0.04745\n",
      "Epoch 249/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0478 - accuracy: 0.9444 - val_loss: 0.0529 - val_accuracy: 0.9364\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 0.04745\n",
      "Epoch 250/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0479 - accuracy: 0.9441 - val_loss: 0.0488 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 0.04745\n",
      "Epoch 251/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0470 - accuracy: 0.9454 - val_loss: 0.0513 - val_accuracy: 0.9391\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 0.04745\n",
      "Epoch 252/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0487 - accuracy: 0.9432 - val_loss: 0.0537 - val_accuracy: 0.9371\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 0.04745\n",
      "Epoch 253/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0463 - accuracy: 0.9462 - val_loss: 0.0527 - val_accuracy: 0.9375\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 0.04745\n",
      "Epoch 254/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0455 - accuracy: 0.9474 - val_loss: 0.0486 - val_accuracy: 0.9432\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 0.04745\n",
      "Epoch 255/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0470 - accuracy: 0.9454 - val_loss: 0.0502 - val_accuracy: 0.9411\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 0.04745\n",
      "Epoch 256/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0475 - accuracy: 0.9448 - val_loss: 0.0526 - val_accuracy: 0.9380\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 0.04745\n",
      "Epoch 257/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0478 - accuracy: 0.9444 - val_loss: 0.0518 - val_accuracy: 0.9381\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 0.04745\n",
      "Epoch 258/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0474 - accuracy: 0.9449 - val_loss: 0.0562 - val_accuracy: 0.9339\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 0.04745\n",
      "Epoch 259/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0458 - accuracy: 0.9470 - val_loss: 0.0517 - val_accuracy: 0.9389\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 0.04745\n",
      "Epoch 260/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0482 - accuracy: 0.9440 - val_loss: 0.0549 - val_accuracy: 0.9341\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 0.04745\n",
      "Epoch 261/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0475 - accuracy: 0.9448 - val_loss: 0.0521 - val_accuracy: 0.9396\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 0.04745\n",
      "Epoch 262/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0471 - accuracy: 0.9453 - val_loss: 0.0501 - val_accuracy: 0.9409\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 0.04745\n",
      "Epoch 263/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0464 - accuracy: 0.9462 - val_loss: 0.0499 - val_accuracy: 0.9411\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 0.04745\n",
      "Epoch 264/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0467 - accuracy: 0.9459 - val_loss: 0.0536 - val_accuracy: 0.9354\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 0.04745\n",
      "Epoch 265/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0455 - accuracy: 0.9475 - val_loss: 0.0502 - val_accuracy: 0.9414\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 0.04745\n",
      "Epoch 266/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0468 - accuracy: 0.9456 - val_loss: 0.0490 - val_accuracy: 0.9426\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 0.04745\n",
      "Epoch 267/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0470 - accuracy: 0.9452 - val_loss: 0.0627 - val_accuracy: 0.9243\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 0.04745\n",
      "Epoch 268/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0464 - accuracy: 0.9464 - val_loss: 0.0514 - val_accuracy: 0.9399\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 0.04745\n",
      "Epoch 269/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0465 - accuracy: 0.9462 - val_loss: 0.0499 - val_accuracy: 0.9412\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 0.04745\n",
      "Epoch 270/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0467 - accuracy: 0.9458 - val_loss: 0.0486 - val_accuracy: 0.9434\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 0.04745\n",
      "Epoch 271/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0477 - accuracy: 0.9447 - val_loss: 0.0488 - val_accuracy: 0.9430\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 0.04745\n",
      "Epoch 272/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0455 - accuracy: 0.9476 - val_loss: 0.0748 - val_accuracy: 0.9098\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 0.04745\n",
      "Epoch 273/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0471 - accuracy: 0.9455 - val_loss: 0.0508 - val_accuracy: 0.9402\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 0.04745\n",
      "Epoch 274/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0469 - accuracy: 0.9456 - val_loss: 0.0539 - val_accuracy: 0.9351\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 0.04745\n",
      "Epoch 275/760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0469 - accuracy: 0.9456 - val_loss: 0.0531 - val_accuracy: 0.9373\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 0.04745\n",
      "Epoch 276/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0459 - accuracy: 0.9469 - val_loss: 0.0503 - val_accuracy: 0.9405\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 0.04745\n",
      "Epoch 277/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0466 - accuracy: 0.9460 - val_loss: 0.0660 - val_accuracy: 0.9205\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 0.04745\n",
      "Epoch 278/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0465 - accuracy: 0.9462 - val_loss: 0.0539 - val_accuracy: 0.9361\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 0.04745\n",
      "Epoch 279/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0463 - accuracy: 0.9464 - val_loss: 0.0652 - val_accuracy: 0.9221\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 0.04745\n",
      "Epoch 280/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0464 - accuracy: 0.9462 - val_loss: 0.0487 - val_accuracy: 0.9425\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 0.04745\n",
      "Epoch 281/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0451 - accuracy: 0.9480 - val_loss: 0.0519 - val_accuracy: 0.9386\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 0.04745\n",
      "Epoch 282/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0455 - accuracy: 0.9475 - val_loss: 0.0539 - val_accuracy: 0.9363\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 0.04745\n",
      "\n",
      "Epoch 00282: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 283/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0396 - accuracy: 0.9553 - val_loss: 0.0446 - val_accuracy: 0.9482\n",
      "\n",
      "Epoch 00283: val_loss improved from 0.04745 to 0.04461, saving model to B_digitalrs.hdf5\n",
      "Epoch 284/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0387 - accuracy: 0.9564 - val_loss: 0.0445 - val_accuracy: 0.9485\n",
      "\n",
      "Epoch 00284: val_loss improved from 0.04461 to 0.04451, saving model to B_digitalrs.hdf5\n",
      "Epoch 285/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0385 - accuracy: 0.9566 - val_loss: 0.0444 - val_accuracy: 0.9484\n",
      "\n",
      "Epoch 00285: val_loss improved from 0.04451 to 0.04441, saving model to B_digitalrs.hdf5\n",
      "Epoch 286/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0384 - accuracy: 0.9567 - val_loss: 0.0461 - val_accuracy: 0.9461\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 0.04441\n",
      "Epoch 287/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0385 - accuracy: 0.9565 - val_loss: 0.0440 - val_accuracy: 0.9488\n",
      "\n",
      "Epoch 00287: val_loss improved from 0.04441 to 0.04402, saving model to B_digitalrs.hdf5\n",
      "Epoch 288/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0380 - accuracy: 0.9570 - val_loss: 0.0445 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 0.04402\n",
      "Epoch 289/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0382 - accuracy: 0.9566 - val_loss: 0.0449 - val_accuracy: 0.9475\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 0.04402\n",
      "Epoch 290/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0380 - accuracy: 0.9570 - val_loss: 0.0444 - val_accuracy: 0.9480\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 0.04402\n",
      "Epoch 291/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0381 - accuracy: 0.9568 - val_loss: 0.0469 - val_accuracy: 0.9454\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 0.04402\n",
      "Epoch 292/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0379 - accuracy: 0.9570 - val_loss: 0.0482 - val_accuracy: 0.9430\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 0.04402\n",
      "Epoch 293/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0382 - accuracy: 0.9564 - val_loss: 0.0435 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00293: val_loss improved from 0.04402 to 0.04354, saving model to B_digitalrs.hdf5\n",
      "Epoch 294/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0377 - accuracy: 0.9573 - val_loss: 0.0473 - val_accuracy: 0.9442\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 0.04354\n",
      "Epoch 295/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0370 - accuracy: 0.9579 - val_loss: 0.0459 - val_accuracy: 0.9457\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 0.04354\n",
      "Epoch 296/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0371 - accuracy: 0.9577 - val_loss: 0.0451 - val_accuracy: 0.9469\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 0.04354\n",
      "Epoch 297/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0376 - accuracy: 0.9572 - val_loss: 0.0449 - val_accuracy: 0.9471\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 0.04354\n",
      "Epoch 298/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0373 - accuracy: 0.9574 - val_loss: 0.0446 - val_accuracy: 0.9476\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 0.04354\n",
      "Epoch 299/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0373 - accuracy: 0.9573 - val_loss: 0.0440 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 0.04354\n",
      "Epoch 300/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0371 - accuracy: 0.9577 - val_loss: 0.0430 - val_accuracy: 0.9494\n",
      "\n",
      "Epoch 00300: val_loss improved from 0.04354 to 0.04298, saving model to B_digitalrs.hdf5\n",
      "Epoch 301/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0370 - accuracy: 0.9577 - val_loss: 0.0437 - val_accuracy: 0.9486\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 0.04298\n",
      "Epoch 302/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0374 - accuracy: 0.9570 - val_loss: 0.0431 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 0.04298\n",
      "Epoch 303/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0366 - accuracy: 0.9581 - val_loss: 0.0462 - val_accuracy: 0.9449\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 0.04298\n",
      "Epoch 304/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0364 - accuracy: 0.9583 - val_loss: 0.0427 - val_accuracy: 0.9496\n",
      "\n",
      "Epoch 00304: val_loss improved from 0.04298 to 0.04274, saving model to B_digitalrs.hdf5\n",
      "Epoch 305/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0377 - accuracy: 0.9567 - val_loss: 0.0439 - val_accuracy: 0.9480\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 0.04274\n",
      "Epoch 306/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0364 - accuracy: 0.9583 - val_loss: 0.0427 - val_accuracy: 0.9494\n",
      "\n",
      "Epoch 00306: val_loss improved from 0.04274 to 0.04268, saving model to B_digitalrs.hdf5\n",
      "Epoch 307/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0365 - accuracy: 0.9581 - val_loss: 0.0437 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 0.04268\n",
      "Epoch 308/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0364 - accuracy: 0.9584 - val_loss: 0.0490 - val_accuracy: 0.9416\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 0.04268\n",
      "Epoch 309/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0368 - accuracy: 0.9577 - val_loss: 0.0425 - val_accuracy: 0.9498\n",
      "\n",
      "Epoch 00309: val_loss improved from 0.04268 to 0.04247, saving model to B_digitalrs.hdf5\n",
      "Epoch 310/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0365 - accuracy: 0.9581 - val_loss: 0.0445 - val_accuracy: 0.9470\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 0.04247\n",
      "Epoch 311/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0365 - accuracy: 0.9579 - val_loss: 0.0426 - val_accuracy: 0.9495\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 0.04247\n",
      "Epoch 312/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0364 - accuracy: 0.9580 - val_loss: 0.0438 - val_accuracy: 0.9478\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 0.04247\n",
      "Epoch 313/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0368 - accuracy: 0.9576 - val_loss: 0.0458 - val_accuracy: 0.9454\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 0.04247\n",
      "Epoch 314/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0364 - accuracy: 0.9581 - val_loss: 0.0446 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 0.04247\n",
      "Epoch 315/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0362 - accuracy: 0.9582 - val_loss: 0.0434 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 0.04247\n",
      "Epoch 316/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0362 - accuracy: 0.9582 - val_loss: 0.0420 - val_accuracy: 0.9505\n",
      "\n",
      "Epoch 00316: val_loss improved from 0.04247 to 0.04197, saving model to B_digitalrs.hdf5\n",
      "Epoch 317/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0358 - accuracy: 0.9587 - val_loss: 0.0457 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 0.04197\n",
      "Epoch 318/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0364 - accuracy: 0.9579 - val_loss: 0.0428 - val_accuracy: 0.9493\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 0.04197\n",
      "Epoch 319/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0359 - accuracy: 0.9585 - val_loss: 0.0434 - val_accuracy: 0.9480\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 0.04197\n",
      "Epoch 320/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0356 - accuracy: 0.9590 - val_loss: 0.0437 - val_accuracy: 0.9477\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 0.04197\n",
      "Epoch 321/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0362 - accuracy: 0.9582 - val_loss: 0.0441 - val_accuracy: 0.9473\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 0.04197\n",
      "Epoch 322/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0355 - accuracy: 0.9591 - val_loss: 0.0425 - val_accuracy: 0.9495\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 0.04197\n",
      "Epoch 323/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0359 - accuracy: 0.9583 - val_loss: 0.0448 - val_accuracy: 0.9465\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 0.04197\n",
      "Epoch 324/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0359 - accuracy: 0.9584 - val_loss: 0.0439 - val_accuracy: 0.9482\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 0.04197\n",
      "Epoch 325/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0359 - accuracy: 0.9584 - val_loss: 0.0430 - val_accuracy: 0.9486\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 0.04197\n",
      "Epoch 326/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0358 - accuracy: 0.9586 - val_loss: 0.0439 - val_accuracy: 0.9477\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 0.04197\n",
      "Epoch 327/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0356 - accuracy: 0.9587 - val_loss: 0.0418 - val_accuracy: 0.9504\n",
      "\n",
      "Epoch 00327: val_loss improved from 0.04197 to 0.04179, saving model to B_digitalrs.hdf5\n",
      "Epoch 328/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0356 - accuracy: 0.9588 - val_loss: 0.0442 - val_accuracy: 0.9471\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 0.04179\n",
      "Epoch 329/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0357 - accuracy: 0.9586 - val_loss: 0.0423 - val_accuracy: 0.9497\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 0.04179\n",
      "Epoch 330/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0364 - accuracy: 0.9576 - val_loss: 0.0424 - val_accuracy: 0.9496\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 0.04179\n",
      "Epoch 331/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0354 - accuracy: 0.9590 - val_loss: 0.0445 - val_accuracy: 0.9466\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 0.04179\n",
      "Epoch 332/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0348 - accuracy: 0.9597 - val_loss: 0.0419 - val_accuracy: 0.9500\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 0.04179\n",
      "Epoch 333/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0351 - accuracy: 0.9593 - val_loss: 0.0420 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 0.04179\n",
      "Epoch 334/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0362 - accuracy: 0.9577 - val_loss: 0.0425 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 0.04179\n",
      "Epoch 335/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0352 - accuracy: 0.9592 - val_loss: 0.0421 - val_accuracy: 0.9496\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 0.04179\n",
      "Epoch 336/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0350 - accuracy: 0.9594 - val_loss: 0.0427 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 0.04179\n",
      "Epoch 337/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0355 - accuracy: 0.9586 - val_loss: 0.0428 - val_accuracy: 0.9490\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 0.04179\n",
      "Epoch 338/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0354 - accuracy: 0.9588 - val_loss: 0.0424 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 0.04179\n",
      "Epoch 339/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0349 - accuracy: 0.9595 - val_loss: 0.0424 - val_accuracy: 0.9493\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 0.04179\n",
      "Epoch 340/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0355 - accuracy: 0.9586 - val_loss: 0.0429 - val_accuracy: 0.9486\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 0.04179\n",
      "Epoch 341/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0351 - accuracy: 0.9591 - val_loss: 0.0427 - val_accuracy: 0.9488\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 0.04179\n",
      "Epoch 342/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0356 - accuracy: 0.9583 - val_loss: 0.0474 - val_accuracy: 0.9424\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 0.04179\n",
      "Epoch 343/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0353 - accuracy: 0.9588 - val_loss: 0.0418 - val_accuracy: 0.9504\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 0.04179\n",
      "Epoch 344/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0348 - accuracy: 0.9596 - val_loss: 0.0453 - val_accuracy: 0.9457\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 0.04179\n",
      "Epoch 345/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0351 - accuracy: 0.9591 - val_loss: 0.0466 - val_accuracy: 0.9437\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 0.04179\n",
      "Epoch 346/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0352 - accuracy: 0.9590 - val_loss: 0.0426 - val_accuracy: 0.9492\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 0.04179\n",
      "Epoch 347/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0353 - accuracy: 0.9587 - val_loss: 0.0473 - val_accuracy: 0.9433\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 0.04179\n",
      "Epoch 348/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0351 - accuracy: 0.9591 - val_loss: 0.0418 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 0.04179\n",
      "Epoch 349/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0348 - accuracy: 0.9595 - val_loss: 0.0428 - val_accuracy: 0.9484\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 0.04179\n",
      "Epoch 350/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0355 - accuracy: 0.9584 - val_loss: 0.0442 - val_accuracy: 0.9469\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 0.04179\n",
      "Epoch 351/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0345 - accuracy: 0.9597 - val_loss: 0.0426 - val_accuracy: 0.9488\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 0.04179\n",
      "Epoch 352/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0351 - accuracy: 0.9589 - val_loss: 0.0431 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 0.04179\n",
      "Epoch 353/760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0353 - accuracy: 0.9587 - val_loss: 0.0462 - val_accuracy: 0.9439\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 0.04179\n",
      "Epoch 354/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0351 - accuracy: 0.9590 - val_loss: 0.0434 - val_accuracy: 0.9480\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 0.04179\n",
      "Epoch 355/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0347 - accuracy: 0.9594 - val_loss: 0.0423 - val_accuracy: 0.9493\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 0.04179\n",
      "Epoch 356/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0341 - accuracy: 0.9601 - val_loss: 0.0422 - val_accuracy: 0.9493\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 0.04179\n",
      "Epoch 357/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0354 - accuracy: 0.9585 - val_loss: 0.0445 - val_accuracy: 0.9465\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 0.04179\n",
      "Epoch 358/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0346 - accuracy: 0.9596 - val_loss: 0.0415 - val_accuracy: 0.9503\n",
      "\n",
      "Epoch 00358: val_loss improved from 0.04179 to 0.04149, saving model to B_digitalrs.hdf5\n",
      "Epoch 359/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0341 - accuracy: 0.9601 - val_loss: 0.0425 - val_accuracy: 0.9489\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 0.04149\n",
      "Epoch 360/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0346 - accuracy: 0.9595 - val_loss: 0.0429 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 0.04149\n",
      "Epoch 361/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0347 - accuracy: 0.9593 - val_loss: 0.0422 - val_accuracy: 0.9493\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 0.04149\n",
      "Epoch 362/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0346 - accuracy: 0.9594 - val_loss: 0.0448 - val_accuracy: 0.9463\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 0.04149\n",
      "Epoch 363/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0349 - accuracy: 0.9591 - val_loss: 0.0457 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 0.04149\n",
      "Epoch 364/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0346 - accuracy: 0.9595 - val_loss: 0.0426 - val_accuracy: 0.9488\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 0.04149\n",
      "Epoch 365/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0342 - accuracy: 0.9599 - val_loss: 0.0487 - val_accuracy: 0.9416\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 0.04149\n",
      "Epoch 366/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0351 - accuracy: 0.9587 - val_loss: 0.0441 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 0.04149\n",
      "Epoch 367/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0349 - accuracy: 0.9590 - val_loss: 0.0422 - val_accuracy: 0.9490\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 0.04149\n",
      "Epoch 368/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0349 - accuracy: 0.9590 - val_loss: 0.0419 - val_accuracy: 0.9493\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 0.04149\n",
      "Epoch 369/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0341 - accuracy: 0.9600 - val_loss: 0.0464 - val_accuracy: 0.9440\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 0.04149\n",
      "Epoch 370/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0342 - accuracy: 0.9600 - val_loss: 0.0411 - val_accuracy: 0.9504\n",
      "\n",
      "Epoch 00370: val_loss improved from 0.04149 to 0.04112, saving model to B_digitalrs.hdf5\n",
      "Epoch 371/760\n",
      "20400/20400 [==============================] - 61s 3ms/step - loss: 0.0347 - accuracy: 0.9592 - val_loss: 0.0432 - val_accuracy: 0.9482\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 0.04112\n",
      "Epoch 372/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0344 - accuracy: 0.9597 - val_loss: 0.0438 - val_accuracy: 0.9471\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 0.04112\n",
      "Epoch 373/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0340 - accuracy: 0.9601 - val_loss: 0.0413 - val_accuracy: 0.9503\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 0.04112\n",
      "Epoch 374/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0344 - accuracy: 0.9596 - val_loss: 0.0418 - val_accuracy: 0.9493\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 0.04112\n",
      "Epoch 375/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0352 - accuracy: 0.9585 - val_loss: 0.0412 - val_accuracy: 0.9503\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 0.04112\n",
      "Epoch 376/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0338 - accuracy: 0.9603 - val_loss: 0.0425 - val_accuracy: 0.9489\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 0.04112\n",
      "Epoch 377/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0348 - accuracy: 0.9590 - val_loss: 0.0414 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 0.04112\n",
      "Epoch 378/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0341 - accuracy: 0.9601 - val_loss: 0.0418 - val_accuracy: 0.9493\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 0.04112\n",
      "Epoch 379/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0342 - accuracy: 0.9597 - val_loss: 0.0470 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 0.04112\n",
      "Epoch 380/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0341 - accuracy: 0.9599 - val_loss: 0.0417 - val_accuracy: 0.9496\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 0.04112\n",
      "Epoch 381/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0342 - accuracy: 0.9598 - val_loss: 0.0416 - val_accuracy: 0.9494\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 0.04112\n",
      "Epoch 382/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0340 - accuracy: 0.9601 - val_loss: 0.0433 - val_accuracy: 0.9471\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 0.04112\n",
      "Epoch 383/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0337 - accuracy: 0.9605 - val_loss: 0.0410 - val_accuracy: 0.9510\n",
      "\n",
      "Epoch 00383: val_loss improved from 0.04112 to 0.04102, saving model to B_digitalrs.hdf5\n",
      "Epoch 384/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0347 - accuracy: 0.9590 - val_loss: 0.0418 - val_accuracy: 0.9495\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 0.04102\n",
      "Epoch 385/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0338 - accuracy: 0.9602 - val_loss: 0.0429 - val_accuracy: 0.9481\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 0.04102\n",
      "Epoch 386/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0336 - accuracy: 0.9606 - val_loss: 0.0413 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 0.04102\n",
      "Epoch 387/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0340 - accuracy: 0.9601 - val_loss: 0.0443 - val_accuracy: 0.9460\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 0.04102\n",
      "Epoch 388/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0342 - accuracy: 0.9597 - val_loss: 0.0440 - val_accuracy: 0.9468\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 0.04102\n",
      "Epoch 389/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0340 - accuracy: 0.9599 - val_loss: 0.0411 - val_accuracy: 0.9504\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 0.04102\n",
      "Epoch 390/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0343 - accuracy: 0.9595 - val_loss: 0.0426 - val_accuracy: 0.9484\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 0.04102\n",
      "Epoch 391/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0342 - accuracy: 0.9597 - val_loss: 0.0514 - val_accuracy: 0.9378\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 0.04102\n",
      "Epoch 392/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0342 - accuracy: 0.9597 - val_loss: 0.0417 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 0.04102\n",
      "Epoch 393/760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0338 - accuracy: 0.9602 - val_loss: 0.0420 - val_accuracy: 0.9494\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 0.04102\n",
      "Epoch 394/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0345 - accuracy: 0.9593 - val_loss: 0.0413 - val_accuracy: 0.9503\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 0.04102\n",
      "Epoch 395/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0340 - accuracy: 0.9599 - val_loss: 0.0413 - val_accuracy: 0.9502\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 0.04102\n",
      "Epoch 396/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0335 - accuracy: 0.9607 - val_loss: 0.0426 - val_accuracy: 0.9484\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 0.04102\n",
      "Epoch 397/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0341 - accuracy: 0.9598 - val_loss: 0.0420 - val_accuracy: 0.9492\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 0.04102\n",
      "Epoch 398/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0340 - accuracy: 0.9599 - val_loss: 0.0438 - val_accuracy: 0.9469\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 0.04102\n",
      "Epoch 399/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0338 - accuracy: 0.9602 - val_loss: 0.0418 - val_accuracy: 0.9496\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 0.04102\n",
      "Epoch 400/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0342 - accuracy: 0.9597 - val_loss: 0.0412 - val_accuracy: 0.9497\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 0.04102\n",
      "Epoch 401/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0334 - accuracy: 0.9608 - val_loss: 0.0423 - val_accuracy: 0.9492\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 0.04102\n",
      "Epoch 402/760\n",
      "20400/20400 [==============================] - 62s 3ms/step - loss: 0.0343 - accuracy: 0.9595 - val_loss: 0.0422 - val_accuracy: 0.9489\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 0.04102\n",
      "Epoch 403/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0333 - accuracy: 0.9608 - val_loss: 0.0412 - val_accuracy: 0.9506\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 0.04102\n",
      "Epoch 404/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0342 - accuracy: 0.9597 - val_loss: 0.0413 - val_accuracy: 0.9503\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 0.04102\n",
      "Epoch 405/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0341 - accuracy: 0.9597 - val_loss: 0.0462 - val_accuracy: 0.9435\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 0.04102\n",
      "Epoch 406/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0350 - accuracy: 0.9586 - val_loss: 0.0484 - val_accuracy: 0.9412\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 0.04102\n",
      "\n",
      "Epoch 00406: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 407/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0316 - accuracy: 0.9632 - val_loss: 0.0405 - val_accuracy: 0.9511\n",
      "\n",
      "Epoch 00407: val_loss improved from 0.04102 to 0.04053, saving model to B_digitalrs.hdf5\n",
      "Epoch 408/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0312 - accuracy: 0.9638 - val_loss: 0.0401 - val_accuracy: 0.9515\n",
      "\n",
      "Epoch 00408: val_loss improved from 0.04053 to 0.04007, saving model to B_digitalrs.hdf5\n",
      "Epoch 409/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0312 - accuracy: 0.9639 - val_loss: 0.0412 - val_accuracy: 0.9504\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 0.04007\n",
      "Epoch 410/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0311 - accuracy: 0.9639 - val_loss: 0.0408 - val_accuracy: 0.9507\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 0.04007\n",
      "Epoch 411/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0311 - accuracy: 0.9639 - val_loss: 0.0406 - val_accuracy: 0.9509\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 0.04007\n",
      "Epoch 412/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0312 - accuracy: 0.9638 - val_loss: 0.0413 - val_accuracy: 0.9503\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 0.04007\n",
      "Epoch 413/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0312 - accuracy: 0.9637 - val_loss: 0.0406 - val_accuracy: 0.9510\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 0.04007\n",
      "Epoch 414/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0311 - accuracy: 0.9638 - val_loss: 0.0398 - val_accuracy: 0.9521\n",
      "\n",
      "Epoch 00414: val_loss improved from 0.04007 to 0.03975, saving model to B_digitalrs.hdf5\n",
      "Epoch 415/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0310 - accuracy: 0.9640 - val_loss: 0.0421 - val_accuracy: 0.9494\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 0.03975\n",
      "Epoch 416/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0310 - accuracy: 0.9640 - val_loss: 0.0409 - val_accuracy: 0.9506\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 0.03975\n",
      "Epoch 417/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0310 - accuracy: 0.9639 - val_loss: 0.0400 - val_accuracy: 0.9518\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 0.03975\n",
      "Epoch 418/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0309 - accuracy: 0.9640 - val_loss: 0.0404 - val_accuracy: 0.9513\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 0.03975\n",
      "Epoch 419/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0310 - accuracy: 0.9640 - val_loss: 0.0399 - val_accuracy: 0.9519\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 0.03975\n",
      "Epoch 420/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0309 - accuracy: 0.9641 - val_loss: 0.0413 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 0.03975\n",
      "Epoch 421/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0308 - accuracy: 0.9642 - val_loss: 0.0409 - val_accuracy: 0.9505\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 0.03975\n",
      "Epoch 422/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0309 - accuracy: 0.9639 - val_loss: 0.0411 - val_accuracy: 0.9504\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 0.03975\n",
      "Epoch 423/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0310 - accuracy: 0.9638 - val_loss: 0.0401 - val_accuracy: 0.9517\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 0.03975\n",
      "Epoch 424/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0308 - accuracy: 0.9640 - val_loss: 0.0400 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 0.03975\n",
      "Epoch 425/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0308 - accuracy: 0.9641 - val_loss: 0.0411 - val_accuracy: 0.9504\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 0.03975\n",
      "Epoch 426/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0309 - accuracy: 0.9641 - val_loss: 0.0398 - val_accuracy: 0.9518\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 0.03975\n",
      "Epoch 427/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0308 - accuracy: 0.9641 - val_loss: 0.0398 - val_accuracy: 0.9519\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 0.03975\n",
      "Epoch 428/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0307 - accuracy: 0.9642 - val_loss: 0.0396 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00428: val_loss improved from 0.03975 to 0.03957, saving model to B_digitalrs.hdf5\n",
      "Epoch 429/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0307 - accuracy: 0.9642 - val_loss: 0.0398 - val_accuracy: 0.9520\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 0.03957\n",
      "Epoch 430/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0307 - accuracy: 0.9642 - val_loss: 0.0400 - val_accuracy: 0.9517\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 0.03957\n",
      "Epoch 431/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0306 - accuracy: 0.9644 - val_loss: 0.0399 - val_accuracy: 0.9517\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 0.03957\n",
      "Epoch 432/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0308 - accuracy: 0.9641 - val_loss: 0.0397 - val_accuracy: 0.9520\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 0.03957\n",
      "Epoch 433/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0307 - accuracy: 0.9642 - val_loss: 0.0399 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 0.03957\n",
      "Epoch 434/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0306 - accuracy: 0.9643 - val_loss: 0.0400 - val_accuracy: 0.9517\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 0.03957\n",
      "Epoch 435/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0305 - accuracy: 0.9644 - val_loss: 0.0409 - val_accuracy: 0.9504\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 0.03957\n",
      "Epoch 436/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0307 - accuracy: 0.9642 - val_loss: 0.0401 - val_accuracy: 0.9513\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 0.03957\n",
      "Epoch 437/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0305 - accuracy: 0.9643 - val_loss: 0.0401 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 0.03957\n",
      "Epoch 438/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0306 - accuracy: 0.9642 - val_loss: 0.0398 - val_accuracy: 0.9518\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 0.03957\n",
      "Epoch 439/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0307 - accuracy: 0.9642 - val_loss: 0.0403 - val_accuracy: 0.9512\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 0.03957\n",
      "Epoch 440/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0307 - accuracy: 0.9641 - val_loss: 0.0400 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 0.03957\n",
      "Epoch 441/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0306 - accuracy: 0.9643 - val_loss: 0.0409 - val_accuracy: 0.9505\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 0.03957\n",
      "Epoch 442/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0305 - accuracy: 0.9643 - val_loss: 0.0400 - val_accuracy: 0.9515\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 0.03957\n",
      "Epoch 443/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0307 - accuracy: 0.9641 - val_loss: 0.0406 - val_accuracy: 0.9509\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 0.03957\n",
      "Epoch 444/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0305 - accuracy: 0.9644 - val_loss: 0.0407 - val_accuracy: 0.9506\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 0.03957\n",
      "Epoch 445/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0306 - accuracy: 0.9642 - val_loss: 0.0396 - val_accuracy: 0.9520\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 0.03957\n",
      "Epoch 446/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0305 - accuracy: 0.9642 - val_loss: 0.0399 - val_accuracy: 0.9517\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 0.03957\n",
      "Epoch 447/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0304 - accuracy: 0.9645 - val_loss: 0.0406 - val_accuracy: 0.9508\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 0.03957\n",
      "Epoch 448/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0305 - accuracy: 0.9643 - val_loss: 0.0397 - val_accuracy: 0.9520\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 0.03957\n",
      "Epoch 449/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0305 - accuracy: 0.9643 - val_loss: 0.0397 - val_accuracy: 0.9520\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 0.03957\n",
      "Epoch 450/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0304 - accuracy: 0.9644 - val_loss: 0.0394 - val_accuracy: 0.9524\n",
      "\n",
      "Epoch 00450: val_loss improved from 0.03957 to 0.03936, saving model to B_digitalrs.hdf5\n",
      "Epoch 451/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0307 - accuracy: 0.9641 - val_loss: 0.0395 - val_accuracy: 0.9520\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 0.03936\n",
      "Epoch 452/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0304 - accuracy: 0.9645 - val_loss: 0.0395 - val_accuracy: 0.9524\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 0.03936\n",
      "Epoch 453/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0303 - accuracy: 0.9646 - val_loss: 0.0402 - val_accuracy: 0.9511\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 0.03936\n",
      "Epoch 454/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0304 - accuracy: 0.9644 - val_loss: 0.0401 - val_accuracy: 0.9513\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 0.03936\n",
      "Epoch 455/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0304 - accuracy: 0.9645 - val_loss: 0.0409 - val_accuracy: 0.9505\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 0.03936\n",
      "Epoch 456/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0304 - accuracy: 0.9644 - val_loss: 0.0396 - val_accuracy: 0.9521\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 0.03936\n",
      "Epoch 457/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0304 - accuracy: 0.9645 - val_loss: 0.0405 - val_accuracy: 0.9509\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 0.03936\n",
      "Epoch 458/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0302 - accuracy: 0.9647 - val_loss: 0.0403 - val_accuracy: 0.9513\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 0.03936\n",
      "Epoch 459/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0303 - accuracy: 0.9646 - val_loss: 0.0402 - val_accuracy: 0.9511\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 0.03936\n",
      "Epoch 460/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0302 - accuracy: 0.9647 - val_loss: 0.0401 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 0.03936\n",
      "Epoch 461/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0302 - accuracy: 0.9646 - val_loss: 0.0403 - val_accuracy: 0.9511\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 0.03936\n",
      "Epoch 462/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0303 - accuracy: 0.9645 - val_loss: 0.0405 - val_accuracy: 0.9510\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 0.03936\n",
      "Epoch 463/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0303 - accuracy: 0.9645 - val_loss: 0.0396 - val_accuracy: 0.9520\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 0.03936\n",
      "Epoch 464/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0304 - accuracy: 0.9644 - val_loss: 0.0399 - val_accuracy: 0.9515\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 0.03936\n",
      "Epoch 465/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0302 - accuracy: 0.9646 - val_loss: 0.0396 - val_accuracy: 0.9521\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 0.03936\n",
      "Epoch 466/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0302 - accuracy: 0.9646 - val_loss: 0.0399 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 0.03936\n",
      "Epoch 467/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0302 - accuracy: 0.9646 - val_loss: 0.0403 - val_accuracy: 0.9512\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 0.03936\n",
      "Epoch 468/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0304 - accuracy: 0.9643 - val_loss: 0.0401 - val_accuracy: 0.9515\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 0.03936\n",
      "Epoch 469/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0302 - accuracy: 0.9646 - val_loss: 0.0400 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 0.03936\n",
      "Epoch 470/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9646 - val_loss: 0.0399 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 0.03936\n",
      "Epoch 471/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0303 - accuracy: 0.9644 - val_loss: 0.0396 - val_accuracy: 0.9520\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 0.03936\n",
      "Epoch 472/760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0302 - accuracy: 0.9646 - val_loss: 0.0405 - val_accuracy: 0.9508\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 0.03936\n",
      "Epoch 473/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9648 - val_loss: 0.0394 - val_accuracy: 0.9522\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 0.03936\n",
      "Epoch 474/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0302 - accuracy: 0.9646 - val_loss: 0.0405 - val_accuracy: 0.9512\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 0.03936\n",
      "Epoch 475/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0300 - accuracy: 0.9648 - val_loss: 0.0412 - val_accuracy: 0.9500\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 0.03936\n",
      "Epoch 476/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9647 - val_loss: 0.0397 - val_accuracy: 0.9518\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 0.03936\n",
      "Epoch 477/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9648 - val_loss: 0.0410 - val_accuracy: 0.9502\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 0.03936\n",
      "Epoch 478/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9647 - val_loss: 0.0401 - val_accuracy: 0.9515\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 0.03936\n",
      "Epoch 479/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0300 - accuracy: 0.9648 - val_loss: 0.0396 - val_accuracy: 0.9520\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 0.03936\n",
      "Epoch 480/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9647 - val_loss: 0.0402 - val_accuracy: 0.9511\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 0.03936\n",
      "Epoch 481/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9647 - val_loss: 0.0398 - val_accuracy: 0.9517\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 0.03936\n",
      "Epoch 482/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0299 - accuracy: 0.9649 - val_loss: 0.0395 - val_accuracy: 0.9520\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 0.03936\n",
      "Epoch 483/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9647 - val_loss: 0.0391 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00483: val_loss improved from 0.03936 to 0.03908, saving model to B_digitalrs.hdf5\n",
      "Epoch 484/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0300 - accuracy: 0.9647 - val_loss: 0.0402 - val_accuracy: 0.9510\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 0.03908\n",
      "Epoch 485/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9647 - val_loss: 0.0396 - val_accuracy: 0.9519\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 0.03908\n",
      "Epoch 486/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9646 - val_loss: 0.0396 - val_accuracy: 0.9518\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 0.03908\n",
      "Epoch 487/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0299 - accuracy: 0.9649 - val_loss: 0.0394 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 0.03908\n",
      "Epoch 488/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0299 - accuracy: 0.9648 - val_loss: 0.0402 - val_accuracy: 0.9512\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 0.03908\n",
      "Epoch 489/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0300 - accuracy: 0.9648 - val_loss: 0.0394 - val_accuracy: 0.9522\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 0.03908\n",
      "Epoch 490/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0298 - accuracy: 0.9650 - val_loss: 0.0404 - val_accuracy: 0.9507\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 0.03908\n",
      "Epoch 491/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9646 - val_loss: 0.0399 - val_accuracy: 0.9518\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 0.03908\n",
      "Epoch 492/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0299 - accuracy: 0.9648 - val_loss: 0.0404 - val_accuracy: 0.9508\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 0.03908\n",
      "Epoch 493/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0301 - accuracy: 0.9645 - val_loss: 0.0403 - val_accuracy: 0.9511\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 0.03908\n",
      "Epoch 494/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0298 - accuracy: 0.9650 - val_loss: 0.0398 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 0.03908\n",
      "Epoch 495/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0297 - accuracy: 0.9651 - val_loss: 0.0404 - val_accuracy: 0.9507\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 0.03908\n",
      "Epoch 496/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0300 - accuracy: 0.9647 - val_loss: 0.0397 - val_accuracy: 0.9518\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 0.03908\n",
      "Epoch 497/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0298 - accuracy: 0.9650 - val_loss: 0.0398 - val_accuracy: 0.9513\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 0.03908\n",
      "Epoch 498/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0299 - accuracy: 0.9648 - val_loss: 0.0418 - val_accuracy: 0.9491\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 0.03908\n",
      "Epoch 499/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0299 - accuracy: 0.9648 - val_loss: 0.0406 - val_accuracy: 0.9506\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 0.03908\n",
      "Epoch 500/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0300 - accuracy: 0.9646 - val_loss: 0.0393 - val_accuracy: 0.9521\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 0.03908\n",
      "Epoch 501/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0297 - accuracy: 0.9651 - val_loss: 0.0396 - val_accuracy: 0.9517\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 0.03908\n",
      "Epoch 502/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0297 - accuracy: 0.9650 - val_loss: 0.0406 - val_accuracy: 0.9505\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 0.03908\n",
      "Epoch 503/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0299 - accuracy: 0.9647 - val_loss: 0.0399 - val_accuracy: 0.9515\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 0.03908\n",
      "Epoch 504/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0298 - accuracy: 0.9649 - val_loss: 0.0393 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 0.03908\n",
      "Epoch 505/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0297 - accuracy: 0.9651 - val_loss: 0.0394 - val_accuracy: 0.9522\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 0.03908\n",
      "Epoch 506/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0298 - accuracy: 0.9649 - val_loss: 0.0395 - val_accuracy: 0.9519\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 0.03908\n",
      "Epoch 507/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0298 - accuracy: 0.9649 - val_loss: 0.0394 - val_accuracy: 0.9519\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 0.03908\n",
      "Epoch 508/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0299 - accuracy: 0.9648 - val_loss: 0.0398 - val_accuracy: 0.9515\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 0.03908\n",
      "Epoch 509/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0298 - accuracy: 0.9649 - val_loss: 0.0405 - val_accuracy: 0.9504\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 0.03908\n",
      "Epoch 510/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0299 - accuracy: 0.9648 - val_loss: 0.0394 - val_accuracy: 0.9521\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 0.03908\n",
      "Epoch 511/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0297 - accuracy: 0.9650 - val_loss: 0.0400 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 0.03908\n",
      "Epoch 512/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0298 - accuracy: 0.9649 - val_loss: 0.0401 - val_accuracy: 0.9509\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 0.03908\n",
      "Epoch 513/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0297 - accuracy: 0.9651 - val_loss: 0.0400 - val_accuracy: 0.9511\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 0.03908\n",
      "Epoch 514/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0297 - accuracy: 0.9651 - val_loss: 0.0394 - val_accuracy: 0.9521\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 0.03908\n",
      "Epoch 515/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0300 - accuracy: 0.9647 - val_loss: 0.0390 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00515: val_loss improved from 0.03908 to 0.03902, saving model to B_digitalrs.hdf5\n",
      "Epoch 516/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0297 - accuracy: 0.9650 - val_loss: 0.0404 - val_accuracy: 0.9507\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 0.03902\n",
      "Epoch 517/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0296 - accuracy: 0.9652 - val_loss: 0.0395 - val_accuracy: 0.9518\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 0.03902\n",
      "Epoch 518/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0296 - accuracy: 0.9652 - val_loss: 0.0400 - val_accuracy: 0.9512\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 0.03902\n",
      "Epoch 519/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0297 - accuracy: 0.9650 - val_loss: 0.0398 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 0.03902\n",
      "\n",
      "Epoch 00519: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "Epoch 520/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0289 - accuracy: 0.9662 - val_loss: 0.0390 - val_accuracy: 0.9524\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 0.03902\n",
      "Epoch 521/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9662 - val_loss: 0.0392 - val_accuracy: 0.9522\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 0.03902\n",
      "Epoch 522/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9663 - val_loss: 0.0388 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00522: val_loss improved from 0.03902 to 0.03878, saving model to B_digitalrs.hdf5\n",
      "Epoch 523/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9662 - val_loss: 0.0392 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 0.03878\n",
      "Epoch 524/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9662 - val_loss: 0.0389 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 0.03878\n",
      "Epoch 525/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9663 - val_loss: 0.0391 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 0.03878\n",
      "Epoch 526/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9662 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 0.03878\n",
      "Epoch 527/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9664 - val_loss: 0.0392 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 0.03878\n",
      "Epoch 528/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9663 - val_loss: 0.0391 - val_accuracy: 0.9522\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 0.03878\n",
      "Epoch 529/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9663 - val_loss: 0.0392 - val_accuracy: 0.9522\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 0.03878\n",
      "Epoch 530/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9663 - val_loss: 0.0390 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 0.03878\n",
      "Epoch 531/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9664 - val_loss: 0.0393 - val_accuracy: 0.9522\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 0.03878\n",
      "Epoch 532/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9663 - val_loss: 0.0392 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 0.03878\n",
      "Epoch 533/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9663 - val_loss: 0.0390 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 0.03878\n",
      "Epoch 534/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9663 - val_loss: 0.0391 - val_accuracy: 0.9524\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 0.03878\n",
      "Epoch 535/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0393 - val_accuracy: 0.9521\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 0.03878\n",
      "Epoch 536/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0392 - val_accuracy: 0.9524: 0.028\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 0.03878\n",
      "Epoch 537/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0391 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 0.03878\n",
      "Epoch 538/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0400 - val_accuracy: 0.9513\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 0.03878\n",
      "Epoch 539/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0288 - accuracy: 0.9663 - val_loss: 0.0390 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 0.03878\n",
      "Epoch 540/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 0.03878\n",
      "Epoch 541/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9665 - val_loss: 0.0389 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 0.03878\n",
      "Epoch 542/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9663 - val_loss: 0.0390 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 0.03878\n",
      "Epoch 543/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9663 - val_loss: 0.0393 - val_accuracy: 0.9522\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 0.03878\n",
      "Epoch 544/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0390 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 0.03878\n",
      "Epoch 545/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9663 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 0.03878\n",
      "Epoch 546/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0391 - val_accuracy: 0.9524\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 0.03878\n",
      "Epoch 547/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9665 - val_loss: 0.0389 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 0.03878\n",
      "Epoch 548/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0400 - val_accuracy: 0.9515\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 0.03878\n",
      "Epoch 549/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9663 - val_loss: 0.0391 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 0.03878\n",
      "Epoch 550/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0392 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 0.03878\n",
      "Epoch 551/760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0286 - accuracy: 0.9665 - val_loss: 0.0392 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 0.03878\n",
      "Epoch 552/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0387 - val_accuracy: 0.9530\n",
      "\n",
      "Epoch 00552: val_loss improved from 0.03878 to 0.03874, saving model to B_digitalrs.hdf5\n",
      "Epoch 553/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0286 - accuracy: 0.9664 - val_loss: 0.0389 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 0.03874\n",
      "Epoch 554/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0390 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 0.03874\n",
      "Epoch 555/760\n",
      "20400/20400 [==============================] - 61s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0392 - val_accuracy: 0.9522\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 0.03874\n",
      "Epoch 556/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0390 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 0.03874\n",
      "Epoch 557/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0287 - accuracy: 0.9664 - val_loss: 0.0392 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 0.03874\n",
      "Epoch 558/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0286 - accuracy: 0.9664 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 0.03874\n",
      "\n",
      "Epoch 00558: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "Epoch 559/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9668 - val_loss: 0.0388 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 0.03874\n",
      "Epoch 560/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9669 - val_loss: 0.0388 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 0.03874\n",
      "Epoch 561/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9668 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 0.03874\n",
      "Epoch 562/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9668 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 0.03874\n",
      "Epoch 563/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9668 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 0.03874\n",
      "Epoch 564/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9668 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 0.03874\n",
      "Epoch 565/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9669 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 0.03874\n",
      "Epoch 566/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9668 - val_loss: 0.0390 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 0.03874\n",
      "Epoch 567/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9668 - val_loss: 0.0388 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 0.03874\n",
      "Epoch 568/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 0.03874\n",
      "Epoch 569/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9669 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 0.03874\n",
      "Epoch 570/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 0.03874\n",
      "Epoch 571/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 0.03874\n",
      "Epoch 572/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 0.03874\n",
      "Epoch 573/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9669 - val_loss: 0.0391 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 0.03874\n",
      "Epoch 574/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 0.03874\n",
      "Epoch 575/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 0.03874\n",
      "Epoch 576/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 0.03874\n",
      "Epoch 577/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 0.03874\n",
      "Epoch 578/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 0.03874\n",
      "Epoch 579/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9669 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 0.03874\n",
      "Epoch 580/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 0.03874\n",
      "Epoch 581/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 0.03874\n",
      "Epoch 582/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 0.03874\n",
      "Epoch 583/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 0.03874\n",
      "Epoch 584/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9525: 0.0283 - accuracy: 0.\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 0.03874\n",
      "Epoch 585/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0284 - accuracy: 0.9668 - val_loss: 0.0390 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 0.03874\n",
      "Epoch 586/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 0.03874\n",
      "Epoch 587/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0389 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 0.03874\n",
      "Epoch 588/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9525\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 0.03874\n",
      "Epoch 589/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 0.03874\n",
      "Epoch 590/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0388 - val_accuracy: 0.9529\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 0.03874\n",
      "Epoch 591/760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 0.03874\n",
      "Epoch 592/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0388 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 0.03874\n",
      "Epoch 593/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0390 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 0.03874\n",
      "Epoch 594/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0283 - accuracy: 0.9669 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 0.03874\n",
      "\n",
      "Epoch 00594: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "Epoch 595/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0388 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 0.03874\n",
      "Epoch 596/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 0.03874\n",
      "Epoch 597/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 0.03874\n",
      "Epoch 598/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 0.03874\n",
      "Epoch 599/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 0.03874\n",
      "Epoch 600/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 0.03874\n",
      "Epoch 601/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9527y\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 0.03874\n",
      "Epoch 602/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 0.03874\n",
      "Epoch 603/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 0.03874\n",
      "Epoch 604/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 0.03874\n",
      "Epoch 605/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 0.03874\n",
      "Epoch 606/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 0.03874\n",
      "Epoch 607/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 0.03874\n",
      "Epoch 608/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 0.03874\n",
      "Epoch 609/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 0.03874\n",
      "Epoch 610/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 0.03874\n",
      "Epoch 611/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 0.03874\n",
      "Epoch 612/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0388 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 0.03874\n",
      "Epoch 613/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 0.03874\n",
      "Epoch 614/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 0.03874\n",
      "Epoch 615/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 0.03874\n",
      "Epoch 616/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 0.03874\n",
      "Epoch 617/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 0.03874\n",
      "Epoch 618/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 0.03874\n",
      "Epoch 619/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 0.03874\n",
      "Epoch 620/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 0.03874\n",
      "Epoch 621/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 0.03874\n",
      "Epoch 622/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 0.03874\n",
      "Epoch 623/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 0.03874\n",
      "Epoch 624/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 0.03874\n",
      "Epoch 625/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0388 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 0.03874\n",
      "Epoch 626/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 0.03874\n",
      "Epoch 627/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 0.03874\n",
      "Epoch 628/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 0.03874\n",
      "Epoch 629/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0390 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 0.03874\n",
      "Epoch 630/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9670 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 0.03874\n",
      "\n",
      "Epoch 00630: ReduceLROnPlateau reducing learning rate to 7.289999985005124e-07.\n",
      "Epoch 631/760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 0.03874\n",
      "Epoch 632/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 0.03874\n",
      "Epoch 633/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 0.03874\n",
      "Epoch 634/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 0.03874\n",
      "Epoch 635/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 0.03874\n",
      "Epoch 636/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 0.03874\n",
      "Epoch 637/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 0.03874\n",
      "Epoch 638/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 0.03874\n",
      "Epoch 639/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 0.03874\n",
      "Epoch 640/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 0.03874\n",
      "Epoch 641/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 0.03874\n",
      "Epoch 642/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 0.03874\n",
      "Epoch 643/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 0.03874\n",
      "Epoch 644/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 0.03874\n",
      "Epoch 645/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 0.03874\n",
      "Epoch 646/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 0.03874\n",
      "Epoch 647/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 0.03874\n",
      "Epoch 648/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 0.03874\n",
      "Epoch 649/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 0.03874\n",
      "Epoch 650/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 0.03874\n",
      "Epoch 651/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 0.03874\n",
      "Epoch 652/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 0.03874\n",
      "Epoch 653/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9527\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 0.03874\n",
      "Epoch 654/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 0.03874\n",
      "Epoch 655/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 0.03874\n",
      "Epoch 656/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 0.03874\n",
      "Epoch 657/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 0.03874\n",
      "Epoch 658/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 0.03874\n",
      "Epoch 659/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 0.03874\n",
      "Epoch 660/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 0.03874\n",
      "Epoch 661/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 0.03874\n",
      "Epoch 662/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 0.03874\n",
      "Epoch 663/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 0.03874\n",
      "Epoch 664/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 0.03874\n",
      "Epoch 665/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 0.03874\n",
      "Epoch 666/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 0.03874\n",
      "\n",
      "Epoch 00666: ReduceLROnPlateau reducing learning rate to 2.1870000637136398e-07.\n",
      "Epoch 667/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 0.03874\n",
      "Epoch 668/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 0.03874\n",
      "Epoch 669/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 0.03874\n",
      "Epoch 670/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 0.03874\n",
      "Epoch 671/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 0.03874\n",
      "Epoch 672/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 0.03874\n",
      "Epoch 673/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 0.03874\n",
      "Epoch 674/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 0.03874\n",
      "Epoch 675/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 0.03874\n",
      "Epoch 676/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 0.03874\n",
      "Epoch 677/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 0.03874\n",
      "Epoch 678/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 0.03874\n",
      "Epoch 679/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 0.03874\n",
      "Epoch 680/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 0.03874\n",
      "Epoch 681/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 0.03874\n",
      "Epoch 682/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 0.03874\n",
      "Epoch 683/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 0.03874\n",
      "Epoch 684/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 0.03874\n",
      "Epoch 685/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 0.03874\n",
      "Epoch 686/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 0.03874\n",
      "Epoch 687/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 0.03874\n",
      "Epoch 688/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 0.03874\n",
      "Epoch 689/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 0.03874\n",
      "Epoch 690/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 0.03874\n",
      "Epoch 691/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 0.03874\n",
      "Epoch 692/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 0.03874\n",
      "Epoch 693/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 0.03874\n",
      "Epoch 694/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 0.03874\n",
      "Epoch 695/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 0.03874\n",
      "Epoch 696/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 0.03874\n",
      "Epoch 697/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 0.03874\n",
      "Epoch 698/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 0.03874\n",
      "Epoch 699/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 0.03874\n",
      "Epoch 700/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 0.03874\n",
      "Epoch 701/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 0.03874\n",
      "Epoch 702/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 0.03874\n",
      "\n",
      "Epoch 00702: ReduceLROnPlateau reducing learning rate to 6.561000276406048e-08.\n",
      "Epoch 703/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 0.03874\n",
      "Epoch 704/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 0.03874\n",
      "Epoch 705/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 0.03874\n",
      "Epoch 706/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 0.03874\n",
      "Epoch 707/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 0.03874\n",
      "Epoch 708/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 0.03874\n",
      "Epoch 709/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 0.03874\n",
      "Epoch 710/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 0.03874\n",
      "Epoch 711/760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 0.03874\n",
      "Epoch 712/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 0.03874\n",
      "Epoch 713/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 0.03874\n",
      "Epoch 714/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 0.03874\n",
      "Epoch 715/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 0.03874\n",
      "Epoch 716/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 0.03874\n",
      "Epoch 717/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 0.03874\n",
      "Epoch 718/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 0.03874\n",
      "Epoch 719/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 0.03874\n",
      "Epoch 720/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 0.03874\n",
      "Epoch 721/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 0.03874\n",
      "Epoch 722/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 0.03874\n",
      "Epoch 723/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 0.03874\n",
      "Epoch 724/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 0.03874\n",
      "Epoch 725/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 0.03874\n",
      "Epoch 726/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 0.03874\n",
      "Epoch 727/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 0.03874\n",
      "Epoch 728/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 0.03874\n",
      "Epoch 729/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 0.03874\n",
      "Epoch 730/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 0.03874\n",
      "Epoch 731/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 0.03874\n",
      "Epoch 732/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 0.03874\n",
      "Epoch 733/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 0.03874\n",
      "Epoch 734/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 0.03874\n",
      "Epoch 735/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 0.03874\n",
      "Epoch 736/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 0.03874\n",
      "Epoch 737/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 0.03874\n",
      "Epoch 738/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 0.03874\n",
      "\n",
      "Epoch 00738: ReduceLROnPlateau reducing learning rate to 1.9683000829218145e-08.\n",
      "Epoch 739/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 0.03874\n",
      "Epoch 740/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 0.03874\n",
      "Epoch 741/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 0.03874\n",
      "Epoch 742/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 0.03874\n",
      "Epoch 743/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 0.03874\n",
      "Epoch 744/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 0.03874\n",
      "Epoch 745/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 0.03874\n",
      "Epoch 746/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 0.03874\n",
      "Epoch 747/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 0.03874\n",
      "Epoch 748/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 0.03874\n",
      "Epoch 749/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 0.03874\n",
      "Epoch 750/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 0.03874\n",
      "Epoch 751/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 0.03874\n",
      "Epoch 752/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 0.03874\n",
      "Epoch 753/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 0.03874\n",
      "Epoch 754/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 0.03874\n",
      "Epoch 755/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 0.03874\n",
      "Epoch 756/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 0.03874\n",
      "Epoch 757/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 0.03874\n",
      "Epoch 758/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 0.03874\n",
      "Epoch 759/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 0.03874\n",
      "Epoch 760/760\n",
      "20400/20400 [==============================] - 60s 3ms/step - loss: 0.0282 - accuracy: 0.9671 - val_loss: 0.0389 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 0.03874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1e49731af88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_data=(X_test, Y_test))\n",
    "# model.fit(X, Y, batch_size=32, epochs=50)\n",
    "def mce(y_true, y_pred):\n",
    "            \n",
    "    evas = K.abs(y_pred - 0.9*y_true)\n",
    "    evas = K.mean(evas, axis=-1)\n",
    "        \n",
    "    return evas\n",
    "\n",
    "def ca1(y_true, y_pred):\n",
    "            \n",
    "    er = .15*mce( -y_true,y_pred )+  2.15*K.mean(K.square(y_pred-y_true))\n",
    "    return er\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.3,\n",
    "                              patience =36,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.0001)\n",
    "\n",
    "filepath=\"B_digitalrs.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')\n",
    "\n",
    "opt = SGD(lr=1e-2, momentum=0.9 )\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train_aug, train_aug_label, batch_size=32, epochs=760, validation_data=(X_test_aug, test_aug_label),\n",
    "          callbacks = [checkpoint,reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('B_digitalr94.h5') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model = load_model('B_digitalr.h5')\n",
    "model.load_weights('B_digitalr94.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_set.class_indices #D:/1A work/jupyter/udac/LIVDET WORK/greenbitfit/train cv2.threshold(grayscaled, 10, 255, cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/1A work/jupyter/udac/LIVDET WORK/pred/digital ['fake', 'real']\n"
     ]
    }
   ],
   "source": [
    " test_img, test_label, Classes = load_imgages_from_folder(\"D:/1A work/jupyter/udac/LIVDET WORK/pred/digital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dat(list_data, label): \n",
    "    augmented_data = list() \n",
    "    data_label = list()\n",
    "    for i in range(0, len(list_data)):\n",
    " \n",
    "            e_img = list_data[i]\n",
    "            e_img = normalize(e_img)\n",
    "            d_label = label[i]\n",
    "  \n",
    "            a_img = e_img \n",
    "            a_img = np.reshape(a_img, (a_img.shape[0], a_img.shape[1], 1))\n",
    "            augmented_data.append(a_img)\n",
    "            data_label.append(d_label)\n",
    "        \n",
    "    return augmented_data, data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aug, test_label_aug = augment_dat(test_img, test_label)\n",
    "test_aug = np.asarray(test_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00231183 -0.01873082  0.01145286 ...  0.73153675  0.5880355\n",
      "  0.5020164 ]\n"
     ]
    }
   ],
   "source": [
    "pred1 = pred.flatten()\n",
    "print(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_list = list()\n",
    "# for i in range(0, len(pred)):\n",
    "#     pred_val = pred[i]\n",
    "#     if pred_val.all() >=0.3001:\n",
    "#         pred_list.append(1)\n",
    "#     else:\n",
    "#         pred_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 64, 64, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(pred).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def thf(pm,th):\n",
    "    fm=pm\n",
    "    for i in range(len(pm)):\n",
    "        if fm.any()>=th:\n",
    "            fm[i] =1\n",
    "        else:\n",
    "            fm[i] =0\n",
    "    return fm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_aug)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pred=[]\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    mn=np.sum(pred[i])/od**2\n",
    "    mean_pred.append(mn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = list()\n",
    "for i in range(0, len(mean_pred)):\n",
    "    pred_val = mean_pred[i]\n",
    "    if pred_val >=0.7101:\n",
    "        pred_list.append(1)\n",
    "    else:\n",
    "        pred_list.append(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1449   51]\n",
      " [ 104  896]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# y_pred = predicted_classes\n",
    "matrix = confusion_matrix(test_label_aug, pred_list)\n",
    "print(matrix)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.938\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array(matrix)\n",
    "print((matrix[:2][0][0]+matrix[:2][1][1])/pred.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_label_aug \n",
    "fa_sum=[]\n",
    "fa_sum1=[]\n",
    "for i in range(1499):\n",
    "    v1=pred[i]\n",
    "    sv=np.mean(v1)\n",
    "    fa_sum.append(sv)\n",
    "    fa_sum1.append(sv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_sum2=[]\n",
    "for i in range(len(fa_sum)):\n",
    "    vl=fa_sum[i]\n",
    "    if vl>=7:\n",
    "        vl=1\n",
    "    else:\n",
    "        vl=0\n",
    "    fa_sum2.append(vl)\n",
    "    \n",
    "    \n",
    "1-np.sum(fa_sum2)/1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_sum=[]\n",
    "re_sum1=[]\n",
    "for i in range(1000):\n",
    "    v1=pred[i+1500]\n",
    "    sv=np.sum(v1)\n",
    "    re_sum.append(sv)\n",
    "    re_sum1.append(sv)\n",
    "\n",
    "    \n",
    "    \n",
    "re_sum2=[]\n",
    "for i in range(len(re_sum)):\n",
    "    vl=re_sum[i]\n",
    "    if vl>=7:\n",
    "        vl=1\n",
    "    else:\n",
    "        vl=0\n",
    "    re_sum2.append(vl)\n",
    "    \n",
    "    \n",
    "np.sum(re_sum2)/1000    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(test_label_aug).shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt=[]\n",
    "pt=[]\n",
    "for i in range(len(pred)):\n",
    "    g1=test_label_aug[i]\n",
    "    gs=np.sum(g1)\n",
    "    p1=pred[i]\n",
    "    p1=thf(p1,0.52)\n",
    "    ps= np.sum(p1)/16\n",
    "    if ps >=.83001:\n",
    "        ps=1\n",
    "    else:\n",
    "        ps=0\n",
    "    pt.append(ps)\n",
    "    gt.append(np.uint8(gs/16))\n",
    "    \n",
    "gt1=np.asarray(gt)    \n",
    "pt1=np.asarray(pt) \n",
    "\n",
    "\n",
    "ompare_order = [1 if i==j else 0 for i, j in zip(gt,pt)] \n",
    "np.sum(ompare_order)/2500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(pt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# # y_pred = predicted_classes\n",
    "# matrix = confusion_matrix(test_label_aug, pred_list)\n",
    "# print(matrix)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9364\n"
     ]
    }
   ],
   "source": [
    "matrix = np.array(matrix)\n",
    "print((matrix[:2][0][0]+matrix[:2][1][1])/pred.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95      1500\n",
      "           1       0.91      0.93      0.92      1000\n",
      "\n",
      "    accuracy                           0.94      2500\n",
      "   macro avg       0.93      0.94      0.93      2500\n",
      "weighted avg       0.94      0.94      0.94      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(test_label_aug, pred_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e499bbfbc8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim=(256,256)\n",
    "im = cv2.imread(\"D:/1A work/jupyter/udac/LIVDET WORK/pred/digital/real/999.JPG\")\n",
    "test_image=cv2.resize(im,dim)\n",
    "test_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)\n",
    "test_image=normalize(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "test_image = np.expand_dims(test_image, axis = 3)\n",
    "pm=model.predict(test_image) \n",
    "f=model.predict(test_image) \n",
    "plt.imshow(f[0],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_image.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         ...,\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         ...,\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         ...,\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         ...,\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         ...,\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         ...,\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm=list()\n",
    "fm=pm\n",
    "for i in range(len(pm)):\n",
    "    if fm.any()>=0.3:\n",
    "        fm[i] =1\n",
    "    else:\n",
    "        fm[i] =0\n",
    "fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_aug, test_label_aug = augment_data(test_img, test_label, 1)\n",
    "test_aug = np.asarray(test_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-64f5f77d9b4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_aug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded_model' is not defined"
     ]
    }
   ],
   "source": [
    "pred = loaded_model.predict(test_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = pred.flatten()\n",
    "print(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = list()\n",
    "for i in range(0, len(pred1)):\n",
    "    pred_val = pred1[i]\n",
    "    if pred_val >=0.50001:\n",
    "        pred_list.append(1)\n",
    "    else:\n",
    "        pred_list.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred_list))\n",
    "# print(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1=cnf(input_im,128) \n",
    "# p1 = MaxPooling2D(pool_size=(4, 4))(x1)\n",
    "# p1=actc(p1)\n",
    "\n",
    "\n",
    "# x2=cnf(p1,256) \n",
    "# p2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "# p2=actc(p2)\n",
    "\n",
    "\n",
    "# x3=cnf(p2,256) \n",
    "# p3 = MaxPooling2D(pool_size=(2, 2))(x3)\n",
    "# p3=actc(p3)\n",
    "\n",
    "\n",
    "# x4=cnf(p2,32) \n",
    "# y = MaxPooling2D(pool_size=(1, 1))(x4)\n",
    "# y= Conv2D(1, kernel_size=9, strides=1, padding='same', kernel_initializer = 'he_normal')(y) \n",
    "# y = MaxPooling2D(pool_size=(2, 2))(y)\n",
    "# y= Conv2D(1, kernel_size=9, strides=1, padding='same', kernel_initializer = 'he_normal')(y) \n",
    " \n",
    "  \n",
    "# model = Model(input_im, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " weight_decay = 1e-4\n",
    "# num_classes = 1\n",
    "# resnet18 = ResNet18(input_shape=(di, di, 1), classes=num_classes, weight_decay=weight_decay)    \n",
    "\n",
    "input_im = Input(shape=(di, di, 1))\n",
    "#input_img=Lambda(lambda x:3*x**2-2*x**3)(input_im) \n",
    "\n",
    "x1=cnh(input_im,32,9,2) \n",
    "x1=cnh(x1,32,9,2) \n",
    "p1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "p1 = Activation('relu')(p1)\n",
    "x2=cnh(x1,64,9,1) \n",
    "x2=cnh(x2,64,9,1) \n",
    "x2=mdsr2(x2,3)\n",
    "p2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "p2 = Activation('relu')(p2)\n",
    "y= Conv2D(1, kernel_size=3, strides=1, padding='same', kernel_initializer = 'he_normal')(p2) \n",
    " \n",
    "  \n",
    "# model = Model(input_im, y)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    " \n",
    " \n",
    " \n",
    "  \n",
    "model = Model(input_im, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
